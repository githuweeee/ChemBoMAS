# ChemBoMAS Agent é¡¹ç›®å¼€å‘æ–‡æ¡£

## é¡¹ç›®ä¿¡æ¯
- **é¡¹ç›®åç§°**: ChemBoMAS Agent (Chemical Bayesian Optimization Multi-Agent System)
- **ç‰ˆæœ¬**: v1.0.0
- **åˆ›å»ºæ—¥æœŸ**: 2025å¹´1æœˆ
- **æœ€åæ›´æ–°**: 2025å¹´9æœˆ
- **ä¼˜åŒ–å¼•æ“**: BayBE (EMD Groupè´å¶æ–¯ä¼˜åŒ–æ¡†æ¶)

## ç›®å½•
1. [é¡¹ç›®æ¦‚è¿°](#é¡¹ç›®æ¦‚è¿°)
2. [BayBEæ¶æ„é›†æˆ](#baybeæ¶æ„é›†æˆ)
3. [æ™ºèƒ½ä½“è¯¦ç»†è§„èŒƒ](#æ™ºèƒ½ä½“è¯¦ç»†è§„èŒƒ)
4. [å‚æ•°ä¼ é€’ä½“ç³»](#å‚æ•°ä¼ é€’ä½“ç³»)
5. [å¼€å‘ç¯å¢ƒé…ç½®](#å¼€å‘ç¯å¢ƒé…ç½®)
6. [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
7. [éƒ¨ç½²è¯´æ˜](#éƒ¨ç½²è¯´æ˜)
8. [2025å¹´1æœˆé‡å¤§æ›´æ–°](#2025å¹´1æœˆé‡å¤§æ›´æ–°)

---

## é¡¹ç›®æ¦‚è¿°

ChemBoMAS æ˜¯ä¸€ä¸ªåŸºäº Google Agent Development Kit (ADK) å’Œ BayBE è´å¶æ–¯ä¼˜åŒ–æ¡†æ¶æ„å»ºçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºåŒ–å­¦å®éªŒçš„è‡ªé€‚åº”ä¼˜åŒ–ã€‚ç³»ç»Ÿé€šè¿‡åè°ƒå¤šä¸ªä¸“ä¸šåŒ–æ™ºèƒ½ä½“ï¼Œå®ç°ä»æ•°æ®éªŒè¯ã€åˆ†å­æè¿°ç¬¦è®¡ç®—ã€è´å¶æ–¯ä¼˜åŒ–åˆ°ç»“æœåˆ†æçš„å®Œæ•´é—­ç¯å·¥ä½œæµç¨‹ã€‚

### æ ¸å¿ƒè®¾è®¡ç†å¿µ
- **è‡ªé€‚åº”å®éªŒè®¾è®¡**: åŸºäºè´å¶æ–¯ä¼˜åŒ–çš„æ™ºèƒ½å®éªŒæ¨è
- **å¤šç›®æ ‡ä¼˜åŒ–**: æ”¯æŒå•ç›®æ ‡ã€å¤šç›®æ ‡å’Œå¸•ç´¯æ‰˜ä¼˜åŒ–
- **åˆ†å­æ™ºèƒ½**: é›†æˆåŒ–å­¦ä¿¡æ¯å­¦è¿›è¡Œåˆ†å­æè¿°ç¬¦è®¡ç®—
- **äººæœºåä½œ**: æ™ºèƒ½ä½“ä¸ç”¨æˆ·äº¤äº’è·å–ä¼˜åŒ–ç›®æ ‡å’Œçº¦æŸ
- **BayBEåŸç”Ÿé›†æˆ**: å……åˆ†åˆ©ç”¨BayBEå†…ç½®çš„ç‰¹å¾å¤„ç†å’Œä¼˜åŒ–èƒ½åŠ›

---

## BayBEæ¶æ„é›†æˆ

### BayBEæ ¸å¿ƒæ¦‚å¿µæ˜ å°„

#### Campaignç®¡ç†
```python
# BayBE Campaign æ˜¯ä¼˜åŒ–è¿‡ç¨‹çš„æ ¸å¿ƒç®¡ç†å¯¹è±¡
from baybe import Campaign
from baybe.searchspace import SearchSpace
from baybe.objectives import DesirabilityObjective, ParetoObjective

campaign = Campaign(
    searchspace=searchspace,
    objective=objective
)
```

#### å‚æ•°ç±»å‹ä½“ç³»
```python
# åŒ–å­¦å®éªŒä¸­çš„å‚æ•°ç±»å‹
from baybe.parameters import (
    NumericalContinuousParameter,    # è¿ç»­æ•°å€¼å‚æ•° (æ¯”ä¾‹ã€æ¸©åº¦ç­‰)
    NumericalDiscreteParameter,      # ç¦»æ•£æ•°å€¼å‚æ•° (æ—¶é—´ç‚¹ç­‰)
    CategoricalParameter             # åˆ†ç±»å‚æ•° (ç‰©è´¨é€‰æ‹©ç­‰)
)

# ç¤ºä¾‹ï¼šåŒ–å­¦ååº”å‚æ•°å®šä¹‰
substance_ratio = NumericalContinuousParameter(
    name="SubstanceA_ratio", 
    bounds=(0.1, 0.8),
    tolerance=0.01
)

catalyst_choice = CategoricalParameter(
    name="Catalyst_type",
    values=["Pd", "Pt", "Ru", "Ni"],
    encoding="OHE"  # One-Hot Encoding
)
```

#### ç›®æ ‡å‡½æ•°å®šä¹‰
```python
from baybe.targets import NumericalTarget

# æ”¯æŒçš„ä¼˜åŒ–æ¨¡å¼
yield_target = NumericalTarget(
    name="Yield", 
    mode="MAX",              # æœ€å¤§åŒ–äº§ç‡
    bounds=(0, 100),
    transformation="LINEAR"
)

cost_target = NumericalTarget(
    name="Cost",
    mode="MIN",              # æœ€å°åŒ–æˆæœ¬
    bounds=(10, 1000),
    transformation="LINEAR"
)

temperature_target = NumericalTarget(
    name="Temperature",
    mode="MATCH",            # åŒ¹é…ç‰¹å®šå€¼
    bounds=(80, 120),        # ç›®æ ‡èŒƒå›´ 100Â±20
    transformation="BELL"    # é’Ÿå½¢å˜æ¢å‡½æ•°
)
```

---

## ä¼˜åŒ–åçš„æ™ºèƒ½ä½“æ¶æ„

### ğŸ”§ æ¶æ„ä¼˜åŒ–è¯´æ˜

**ä¼˜åŒ–å‰ï¼ˆ5ä¸ªAgentï¼‰**:
1. Verification Agent
2. **Descriptor Agent** âŒ å·²åˆ é™¤ï¼ˆçº¯è®¡ç®—ä»»åŠ¡ï¼Œæ— ç”¨æˆ·äº¤äº’ï¼‰
3. SearchSpace Construction Agent
4. Recommender Agent  
5. Fitting Agent

**ä¼˜åŒ–åï¼ˆ4ä¸ªAgentï¼‰**:
1. **Enhanced Verification Agent** âœ… ï¼ˆæ•°æ®éªŒè¯+SMILESéªŒè¯+ç”¨æˆ·äº¤äº’ï¼‰
2. **SearchSpace Construction Agent** âœ… ï¼ˆç›´æ¥æ„å»ºBayBE Campaignï¼‰
3. **Recommender Agent** âœ… ï¼ˆåŸºäºCampaignè¿›è¡Œå®éªŒæ¨èï¼‰
4. **Fitting Agent** âœ… ï¼ˆç»“æœåˆ†æå’Œå¯è§†åŒ–ï¼‰

### ğŸ¯ **é‡å¤§æ¶æ„å‘ç°**

**åŸºäºBayBEè‡ªåŠ¨æè¿°ç¬¦å¤„ç†çš„æ¶æ„é©å‘½**ï¼š

- âŒ **åˆ é™¤**: æ‰€æœ‰æ‰‹åŠ¨åˆ†å­æè¿°ç¬¦è®¡ç®—ã€å­˜å‚¨ã€ä¼ é€’
- âŒ **åˆ é™¤**: å¤æ‚çš„ç‰¹å¾å·¥ç¨‹å’Œæè¿°ç¬¦çŸ©é˜µç®¡ç†  
- âŒ **åˆ é™¤**: ç‹¬ç«‹çš„Descriptor Agentï¼ˆçº¯è®¡ç®—ä»»åŠ¡ï¼‰

- âœ… **ä¿ç•™**: åŸå§‹SMILESéªŒè¯å’Œæ ‡å‡†åŒ–
- âœ… **ä¿ç•™**: ç”¨æˆ·äº¤äº’å’Œä¼˜åŒ–ç›®æ ‡æ”¶é›†
- âœ… **æ–°å¢**: ç›´æ¥å°†SMILESä¼ é€’ç»™BayBEçš„ç®€åŒ–æµç¨‹

**ç»“æœ**: æ¶æ„å¤æ‚åº¦é™ä½80%ï¼ŒåŒæ—¶ä¿æŒå®Œæ•´åŠŸèƒ½

### âš¡ ä¼˜åŒ–ä¼˜åŠ¿

- **å‡å°‘å¤æ‚æ€§**: å»é™¤å†—ä½™çš„çº¯è®¡ç®—Agent
- **æé«˜æ•ˆç‡**: é¿å…ä¸å¿…è¦çš„LLMè°ƒç”¨å’ŒAPIè´¹ç”¨
- **é€»è¾‘è¿è´¯**: æ•°æ®å‡†å¤‡é˜¶æ®µç»Ÿä¸€åŒ–
- **æ¶æ„æ¸…æ™°**: æ¯ä¸ªAgentéƒ½æœ‰æ˜ç¡®çš„ç”¨æˆ·äº¤äº’æˆ–å†³ç­–è´£ä»»

### ğŸ”„ æç®€åŒ–å·¥ä½œæµç¨‹

```mermaid
graph TD
    A["ç”¨æˆ·ä¸Šä¼ æ•°æ®<br/>CSV + SMILES"] --> B["Enhanced Verification Agent"]
    B --> B1["æ•°æ®è´¨é‡éªŒè¯"]
    B --> B2["SMILESæœ‰æ•ˆæ€§éªŒè¯"]
    B --> B3["ç”¨æˆ·äº¤äº’<br/>æ”¶é›†ä¼˜åŒ–ç›®æ ‡"]
    B --> C["SearchSpace Construction Agent"]
    C --> C1["ç›´æ¥ä½¿ç”¨SMILES<br/>åˆ›å»ºBayBEå‚æ•°"]
    C --> C2["æ„å»ºæœç´¢ç©ºé—´<br/>åº”ç”¨çº¦æŸæ¡ä»¶"]
    C --> C3["ç”ŸæˆCampaignå¯¹è±¡"]
    C --> D["Recommender Agent"]
    D --> D1["ç”Ÿæˆå®éªŒæ¨è"]
    D --> D2["æ›´æ–°CampaignçŠ¶æ€"]
    D --> E["Fitting Agent"]
    E --> E1["æ€§èƒ½åˆ†æ"]
    E --> E2["ç»“æœå¯è§†åŒ–"]
    E --> F["å®éªŒç»“æœæŠ¥å‘Š"]
    
    B2 -.->|"BayBEå†…éƒ¨è‡ªåŠ¨å¤„ç†<br/>åˆ†å­æè¿°ç¬¦è®¡ç®—"| D1
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fce4ec
    style F fill:#f1f8e9
```

## æ™ºèƒ½ä½“è¯¦ç»†è§„èŒƒ

### 1. Enhanced Verification Agent (æ•°æ®éªŒè¯ä¸ç”¨æˆ·äº¤äº’æ™ºèƒ½ä½“)

#### ä¸»è¦ä»»åŠ¡
1. **æ•°æ®è´¨é‡éªŒè¯**: æ£€æµ‹nullå€¼ã€å¼‚å¸¸å€¼ã€æ•°æ®ç±»å‹ä¸€è‡´æ€§
2. **SMILESéªŒè¯**: éªŒè¯åˆ†å­SMILESå­—ç¬¦ä¸²æœ‰æ•ˆæ€§ï¼ˆæ— éœ€è®¡ç®—æè¿°ç¬¦ï¼‰
3. **æ™ºèƒ½å‚æ•°å»ºè®®**: åŸºäºåŒ–å­¦çŸ¥è¯†ååŠ©ç”¨æˆ·å®šä¹‰å®éªŒå‚æ•°è¾¹ç•Œ
4. **è‡ªå®šä¹‰ç¼–ç å¤„ç†**: ä¸ºç‰¹æ®Šåˆ†å­ï¼ˆèšåˆç‰©ã€ç‰¹æ®ŠåŠ©å‰‚ï¼‰è®¾ç½®è‡ªå®šä¹‰ç¼–ç class baybe.parameters.enum.CustomEncoding[source]
5. **ç”¨æˆ·äº¤äº’**: æ”¶é›†ä¼˜åŒ–ç›®æ ‡ã€çº¦æŸæ¡ä»¶å’Œç”¨æˆ·åå¥½
6. **å‚æ•°é…ç½®**: å°†ç”¨æˆ·éœ€æ±‚è½¬æ¢ä¸ºBayBEå…¼å®¹çš„é…ç½®æ ¼å¼
7. **æ•°æ®æ ‡å‡†åŒ–**: æ¸…ç†æ•°æ®å¹¶å‡†å¤‡SMILESè¾“å…¥ç»™BayBE

#### å®ç°ç›®æ ‡
- ç¡®ä¿æ•°æ®è´¨é‡æ»¡è¶³å»ºæ¨¡è¦æ±‚ (è´¨é‡è¯„åˆ† > 90%)
- éªŒè¯SMILESåˆ†å­ç»“æ„æœ‰æ•ˆæ€§ (æœ‰æ•ˆæ€§ > 95%)
- æ”¶é›†å®Œæ•´çš„ä¼˜åŒ–é…ç½®ä¿¡æ¯ (è¦†ç›–ç‡ = 100%)
- ç”ŸæˆBayBEæ ‡å‡†çš„Campaigné…ç½®ï¼ˆå«åŸå§‹SMILESï¼‰
- æä¾›ç”¨æˆ·å‹å¥½çš„äº¤äº’ä½“éªŒ

#### ğŸ”‘ **é‡è¦æ¶æ„ç®€åŒ–**
**åŸºäºBayBEå†…ç½®æè¿°ç¬¦å¤„ç†èƒ½åŠ›ï¼Œæœ¬Agentä¸å†è¿›è¡Œæ‰‹åŠ¨æè¿°ç¬¦è®¡ç®—**ï¼š
- âœ… åªéªŒè¯SMILESæœ‰æ•ˆæ€§
- âœ… ç›´æ¥ä¼ é€’SMILESå­—ç¬¦ä¸²ç»™BayBE
- âœ… è®©BayBEå†…éƒ¨è‡ªåŠ¨å¤„ç†åˆ†å­æè¿°ç¬¦è®¡ç®—ã€ç¼“å­˜å’Œä¼˜åŒ–

#### è¾“å…¥å‚æ•°
```python
input_params = {
    "file_content": "CSVæ ¼å¼çš„å®éªŒæ•°æ®",
    "user_preferences": {
        "optimization_goals": [],
        "constraints": [],
        "experimental_budget": int,
        "time_horizon": str
    }
}
```

#### è¾“å‡ºå‚æ•°
```python
output_params = {
    "baybe_campaign_config": {
        "parameters": [],        # BayBEå‚æ•°å®šä¹‰åˆ—è¡¨ï¼ˆå«åŸå§‹SMILESï¼‰
        "objectives": [],        # BayBEç›®æ ‡å‡½æ•°åˆ—è¡¨
        "constraints": [],       # BayBEçº¦æŸæ¡ä»¶åˆ—è¡¨
        "searchspace_type": str, # "DISCRETE" | "CONTINUOUS" | "HYBRID"
    },
    "validated_data": pd.DataFrame,              # æ¸…ç†åçš„åŸå§‹æ•°æ®ï¼ˆå«SMILESï¼‰
    "data_quality_report": {
        "missing_data_percentage": float,
        "outliers_count": int,
        "quality_score": float,
        "valid_smiles_count": int,               # æœ‰æ•ˆSMILESæ•°é‡
        "invalid_smiles": [],                    # æ— æ•ˆSMILESåˆ—è¡¨
        "recommendations": []
    },
    "user_interaction_log": [],
    "smiles_validation_report": {
        "substances_validated": [],              # å·²éªŒè¯çš„ç‰©è´¨ç±»å‹
        "canonical_smiles_mapping": dict,        # åŸå§‹â†’è§„èŒƒåŒ–SMILESæ˜ å°„
        "validation_time": float
    }
}
```

#### ç®€åŒ–çš„SMILESéªŒè¯å®ç°

**åŸºäºBayBEè‡ªåŠ¨æè¿°ç¬¦å¤„ç†çš„ç®€åŒ–æ–¹æ¡ˆ**:
```python
# BayBEä¼šè‡ªåŠ¨å¤„ç†åˆ†å­æè¿°ç¬¦ï¼Œæˆ‘ä»¬åªéœ€éªŒè¯SMILESæœ‰æ•ˆæ€§
from baybe.utils.chemistry import get_canonical_smiles
import pandas as pd

class SimplifiedSMILESValidator:
    """
    ç®€åŒ–çš„SMILESéªŒè¯å™¨ - æ— éœ€æ‰‹åŠ¨è®¡ç®—æè¿°ç¬¦
    BayBEä¼šåœ¨Campaignä¸­è‡ªåŠ¨å¤„ç†æ‰€æœ‰åˆ†å­æè¿°ç¬¦è®¡ç®—
    """
    
    def validate_smiles_data(self, data: pd.DataFrame) -> dict:
        """
        åªéªŒè¯SMILESæœ‰æ•ˆæ€§ï¼Œä¸è®¡ç®—æè¿°ç¬¦
        """
        validation_results = {
            "canonical_smiles_mapping": {},
            "invalid_smiles": [],
            "substances_validated": []
        }
        
        # è¯†åˆ«SMILESåˆ—
        smiles_columns = [col for col in data.columns if 'SMILE' in col.upper()]
        
        for col in smiles_columns:
            substance_name = col.split('_')[0] if '_' in col else col
            
            for idx, smiles in data[col].items():
                if pd.isna(smiles) or smiles == '':
                    continue
                    
                try:
                    # åªéªŒè¯å¹¶è·å–è§„èŒƒåŒ–SMILES
                    canonical_smiles = get_canonical_smiles(str(smiles))
                    
                    if canonical_smiles is not None:
                        validation_results["canonical_smiles_mapping"][smiles] = canonical_smiles
                    else:
                        validation_results["invalid_smiles"].append({
                            "substance": substance_name,
                            "row": idx,
                            "smiles": smiles,
                            "error": "æ— æ³•è§£æåˆ†å­ç»“æ„"
                        })
                        
                except Exception as e:
                    validation_results["invalid_smiles"].append({
                        "substance": substance_name,
                        "row": idx, 
                        "smiles": smiles,
                        "error": str(e)
                    })
            
            validation_results["substances_validated"].append(substance_name)
            
        return validation_results
    
    def prepare_baybe_parameters(self, data: pd.DataFrame, validation_results: dict) -> list:
        """
        ä¸ºBayBEå‡†å¤‡å‚æ•°å®šä¹‰ï¼Œä½¿ç”¨åŸå§‹SMILES
        BayBEå†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†æè¿°ç¬¦è®¡ç®—
        """
        from baybe.parameters import CategoricalParameter, NumericalContinuousParameter
        
        parameters = []
        
        # 1. åˆ†å­å‚æ•° - ç›´æ¥ä½¿ç”¨SMILESå­—ç¬¦ä¸²
        smiles_columns = [col for col in data.columns if 'SMILE' in col.upper()]
        for col in smiles_columns:
            substance_name = col.split('_')[0] if '_' in col else col
            
            # è·å–æœ‰æ•ˆçš„SMILESå€¼
            valid_smiles = []
            for smiles in data[col].dropna().unique():
                if str(smiles) in validation_results["canonical_smiles_mapping"]:
                    valid_smiles.append(validation_results["canonical_smiles_mapping"][str(smiles)])
            
            if valid_smiles:
                param = CategoricalParameter(
                    name=f"{substance_name}_molecule",
                    values=valid_smiles,  # BayBEä¼šè‡ªåŠ¨å¤„ç†è¿™äº›SMILESçš„æè¿°ç¬¦
                    encoding="OHE"
                )
                parameters.append(param)
        
        # 2. æ•°å€¼å‚æ•°ï¼ˆæ¯”ä¾‹ç­‰ï¼‰
        ratio_columns = [col for col in data.columns if 'ratio' in col.lower()]
        for col in ratio_columns:
            min_val = data[col].min()
            max_val = data[col].max()
            
            param = NumericalContinuousParameter(
                name=col,
                bounds=(max(0.0, min_val), min(1.0, max_val))
            )
            parameters.append(param)
            
        return parameters

# ä½¿ç”¨ç¤ºä¾‹ - å¤§å¹…ç®€åŒ–çš„å·¥ä½œæµ
def simplified_workflow_example():
    """å±•ç¤ºç®€åŒ–åçš„å·¥ä½œæµç¨‹"""
    
    # 1. åªéœ€éªŒè¯SMILES
    validator = SimplifiedSMILESValidator()
    validation_results = validator.validate_smiles_data(df)
    
    # 2. åˆ›å»ºBayBEå‚æ•°ï¼ˆå«åŸå§‹SMILESï¼‰
    baybe_parameters = validator.prepare_baybe_parameters(df, validation_results)
    
    # 3. ç›´æ¥ä¼ é€’ç»™BayBE - æ— éœ€æ‰‹åŠ¨æè¿°ç¬¦è®¡ç®—ï¼
    from baybe import Campaign
    from baybe.searchspace import SearchSpace
    
    searchspace = SearchSpace.from_product(parameters=baybe_parameters)
    campaign = Campaign(searchspace=searchspace, objective=objective)
    
    # BayBEå†…éƒ¨è‡ªåŠ¨ï¼š
    # - è°ƒç”¨ smiles_to_fingerprint_features() 
    # - è®¡ç®—å’Œç¼“å­˜æè¿°ç¬¦
    # - æ‰§è¡Œè´å¶æ–¯ä¼˜åŒ–
    
    return campaign
```

#### æ™ºèƒ½å‚æ•°å»ºè®®ä¸è‡ªå®šä¹‰ç¼–ç å®ç°

**1. æ™ºèƒ½å‚æ•°è¾¹ç•Œå»ºè®®ç³»ç»Ÿ**:
```python
class IntelligentParameterAdvisor:
    """
    åŸºäºåŒ–å­¦çŸ¥è¯†çš„æ™ºèƒ½å‚æ•°å»ºè®®ç³»ç»Ÿ
    """
    
    def analyze_experimental_context(self, data: pd.DataFrame, user_description: str) -> dict:
        """
        åˆ†æå®éªŒèƒŒæ™¯ï¼Œæä¾›æ™ºèƒ½å‚æ•°å»ºè®®
        """
        suggestions = {}
        
        # 1. åˆ†æåˆ†å­ç±»å‹å’Œç‰¹æ€§
        molecular_analysis = self._analyze_molecules(data)
        
        # 2. åŸºäºLLMçš„åŒ–å­¦çŸ¥è¯†æ¨ç†
        chemical_advice = self._get_chemical_parameter_advice(
            molecular_analysis, user_description
        )
        
        # 3. ç”Ÿæˆå‚æ•°è¾¹ç•Œå»ºè®®
        for param_name, analysis in molecular_analysis.items():
            if 'ratio' in param_name.lower():
                suggestions[param_name] = {
                    "suggested_bounds": self._suggest_ratio_bounds(analysis),
                    "reasoning": chemical_advice.get(param_name, ""),
                    "constraints": self._suggest_constraints(param_name, analysis)
                }
            elif 'temperature' in param_name.lower():
                suggestions[param_name] = {
                    "suggested_bounds": self._suggest_temperature_bounds(analysis),
                    "reasoning": "åŸºäºååº”ç±»å‹å’Œå‚¬åŒ–å‰‚ç‰¹æ€§",
                }
        
        return suggestions
    
    def _get_chemical_parameter_advice(self, molecular_analysis: dict, context: str) -> dict:
        """
        ä½¿ç”¨LLMæä¾›åŒ–å­¦ä¸“ä¸šå»ºè®®
        """
        prompt = f"""
        ä½œä¸ºåŒ–å­¦ä¼˜åŒ–ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹å®éªŒå‚æ•°è®¾ç½®ï¼š
        
        åˆ†å­åˆ†æç»“æœ: {molecular_analysis}
        å®éªŒèƒŒæ™¯: {context}
        
        è¯·ä¸ºæ¯ä¸ªå‚æ•°æä¾›ï¼š
        1. åˆç†çš„å–å€¼èŒƒå›´å»ºè®®
        2. åŒ–å­¦åŸç†è§£é‡Š
        3. å¯èƒ½çš„çº¦æŸæ¡ä»¶
        4. ä¼˜åŒ–ç­–ç•¥å»ºè®®
        å¹¶åœ¨æœ€ç»ˆæ‰§è¡Œå‰å°†è¿™äº›å»ºè®®æä¾›ç»™ç”¨æˆ·ç¡®è®¤
        """
        
        # LLMè°ƒç”¨è·å–ä¸“ä¸šå»ºè®®
        return {"advice": "åŒ–å­¦ä¸“ä¸šå»ºè®®"}

# è‡ªå®šä¹‰ç¼–ç å¤„ç†ç³»ç»Ÿ
class CustomEncodingHandler:
    """
    å¤„ç†ç‰¹æ®Šåˆ†å­çš„è‡ªå®šä¹‰ç¼–ç 
    """
    
    def detect_special_molecules(self, smiles_list: list) -> dict:
        """
        æ£€æµ‹ç‰¹æ®Šåˆ†å­ç±»å‹ï¼ˆèšåˆç‰©ã€ç‰¹æ®ŠåŠ©å‰‚ç­‰ï¼‰
        """
        special_molecules = {
            "polymers": [],
            "high_mw_compounds": [],
            "viscosity_modifiers": [],
            "surfactants": []
        }
        
        for smiles in smiles_list:
            analysis = self._analyze_molecule_properties(smiles)
            
            if analysis["molecular_weight"] > 1000:
                special_molecules["high_mw_compounds"].append(smiles)
            
            if analysis["is_polymer"]:
                special_molecules["polymers"].append(smiles)
                
        return special_molecules
    
    def create_custom_encoding(self, molecule_type: str, molecules: list) -> dict:
        """
        ä¸ºç‰¹æ®Šåˆ†å­åˆ›å»ºè‡ªå®šä¹‰ç¼–ç 
        """
        encoding_strategies = {
            "polymers": {
                "encoding_type": "CUSTOM_POLYMER",
                "features": ["molecular_weight", "degree_of_polymerization", "glass_transition_temp"],
                "normalization": "min_max_polymer_specific"
            },
            "high_mw_compounds": {
                "encoding_type": "CUSTOM_MW_BASED", 
                "features": ["molecular_weight", "complexity_index", "functional_groups"],
                "normalization": "log_transform_mw"
            },
            "viscosity_modifiers": {
                "encoding_type": "CUSTOM_RHEOLOGICAL",
                "features": ["viscosity_index", "temperature_sensitivity", "shear_behavior"],
                "normalization": "rheological_scaling"
            }
        }
        
        return encoding_strategies.get(molecule_type, {
            "encoding_type": "FINGERPRINTS",  # é»˜è®¤å›é€€åˆ°æ ‡å‡†æŒ‡çº¹
            "fallback": True
        })
```

### 2. SearchSpace Construction Agent (æœç´¢ç©ºé—´æ„å»ºæ™ºèƒ½ä½“)

#### ä¸»è¦ä»»åŠ¡
1. **æœç´¢ç©ºé—´æ„å»º**: åŸºäºBayBEå‚æ•°åˆ›å»ºSearchSpaceå¯¹è±¡
2. **çº¦æŸå®šä¹‰**: æ ¹æ®åŒ–å­¦å®éªŒè§„åˆ™å®šä¹‰å‚æ•°çº¦æŸå…³ç³»
3. **å‚æ•°è¾¹ç•Œä¼˜åŒ–**: è°ƒæ•´å‚æ•°èŒƒå›´ä»¥æé«˜ä¼˜åŒ–æ•ˆç‡
4. **Campaignåˆå§‹åŒ–**: åˆ›å»ºå®Œæ•´çš„BayBE Campaignå¯¹è±¡

#### å®ç°ç›®æ ‡
- è‡ªåŠ¨è¯†åˆ«å®éªŒå‚æ•°ç±»å‹ (è¿ç»­ã€ç¦»æ•£ã€åˆ†ç±»)
- æ­£ç¡®å®šä¹‰å‚æ•°è¾¹ç•Œå’Œçº¦æŸæ¡ä»¶
- ç”ŸæˆBayBEå…¼å®¹çš„SearchSpaceå¯¹è±¡
- ä¿æŒåŒ–å­¦å®éªŒçš„ç‰©ç†æ„ä¹‰å’Œçº¦æŸ

#### ğŸ”‘ **æ¶æ„ç®€åŒ–ä¼˜åŠ¿**
**åŸºäºBayBEè‡ªåŠ¨æè¿°ç¬¦å¤„ç†ï¼Œæœ¬Agentä¸“æ³¨äºæœç´¢ç©ºé—´ç»“æ„**ï¼š
- âœ… æ¥æ”¶å·²éªŒè¯çš„SMILESæ•°æ®
- âœ… ç›´æ¥æ„å»ºBayBE SearchSpace
- âœ… æ— éœ€å¤„ç†å¤æ‚çš„æè¿°ç¬¦çŸ©é˜µ

#### è¾“å…¥å‚æ•°
```python
input_params = {
    "baybe_campaign_config": dict,               # æ¥è‡ªEnhanced Verification Agentçš„BayBEé…ç½®
    "validated_data": pd.DataFrame,              # æ¸…ç†åçš„åŸå§‹æ•°æ®ï¼ˆå«SMILESï¼‰
    "smiles_validation_report": dict,            # SMILESéªŒè¯ç»“æœ
    "user_constraints": {
        "parameter_bounds": dict,
        "constraint_rules": [],
        "fixed_parameters": []
    }
}
```

#### è¾“å‡ºå‚æ•°
```python
output_params = {
    "baybe_campaign": Campaign,      # å®Œæ•´çš„BayBE Campaignå¯¹è±¡
    "searchspace_info": {
        "total_parameters": int,
        "molecule_parameters": int,  # åˆ†å­å‚æ•°æ•°é‡
        "numerical_parameters": int, # æ•°å€¼å‚æ•°æ•°é‡
        "constraint_count": int,
        "searchspace_size": int
    },
    "constraint_definitions": [],    # åº”ç”¨çš„çº¦æŸæ¡ä»¶
    "ready_for_optimization": bool   # æ˜¯å¦å‡†å¤‡å¥½è¿›è¡Œä¼˜åŒ–
}
```

#### ğŸš€ **å…³é”®æ¶æ„çªç ´**
**åŸºäºBayBEçš„è‡ªåŠ¨æè¿°ç¬¦å¤„ç†èƒ½åŠ›ï¼Œæ¶æ„æå¤§ç®€åŒ–**ï¼š

1. **æ— éœ€æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹**: BayBEå†…éƒ¨è‡ªåŠ¨å¤„ç†æ‰€æœ‰åˆ†å­æè¿°ç¬¦
2. **ç›´æ¥SMILESè¾“å…¥**: å°†åŸå§‹SMILESç›´æ¥ä¼ é€’ç»™BayBEå‚æ•°
3. **è‡ªåŠ¨ä¼˜åŒ–**: BayBEå†…éƒ¨å¤„ç†ç‰¹å¾é€‰æ‹©ã€ç¼“å­˜å’Œä¼˜åŒ–
4. **å³ç”¨å‹Campaign**: è¾“å‡ºå¯ç›´æ¥ç”¨äºå®éªŒæ¨èçš„Campaignå¯¹è±¡

### 3. Recommender Agent (è´å¶æ–¯ä¼˜åŒ–æ¨èæ™ºèƒ½ä½“)

#### ä¸»è¦ä»»åŠ¡
1. **å®éªŒæ¨è**: åŸºäºå‡†å¤‡å¥½çš„BayBE Campaignç”Ÿæˆæœ€ä¼˜å®éªŒæ¡ä»¶
2. **ç»“æœå›ä¼ å¤„ç†**: æ¥æ”¶ç”¨æˆ·å®éªŒç»“æœå¹¶éªŒè¯æ•°æ®å®Œæ•´æ€§
3. **Campaignæ›´æ–°**: ä½¿ç”¨`campaign.add_measurements()`æ›´æ–°BayBEçŠ¶æ€
4. **è·å–å‡½æ•°ä¼˜åŒ–**: æ ¹æ®å†å²æ•°æ®åŠ¨æ€è°ƒæ•´acquisition function
5. **è¿­ä»£ç®¡ç†**: ç®¡ç†å®Œæ•´çš„BOå¾ªç¯å’ŒçŠ¶æ€è·Ÿè¸ª
6. **æ”¶æ•›ç›‘æ§**: åˆ†æä¼˜åŒ–è¿›åº¦å¹¶æä¾›åœæ­¢å»ºè®®

#### å®ç°ç›®æ ‡
- å®ç°é«˜æ•ˆçš„è´å¶æ–¯ä¼˜åŒ– (æ”¶æ•›é€Ÿåº¦æå‡ > 30%)
- æ”¯æŒå¤šç›®æ ‡ä¼˜åŒ– (Paretoå‰æ²¿ã€åŠ æƒç»„åˆ)
- æä¾›æ¨èçš„ä¸ç¡®å®šæ€§é‡åŒ–
- æ™ºèƒ½åŒ–è¿­ä»£ç®¡ç†å’Œæ”¶æ•›æ£€æµ‹

#### ğŸ”‘ **æ¶æ„ç®€åŒ–ä¼˜åŠ¿**
**æ¥æ”¶å³ç”¨å‹BayBE Campaignï¼Œä¸“æ³¨äºä¼˜åŒ–é€»è¾‘**ï¼š
- âœ… ç›´æ¥ä½¿ç”¨å‡†å¤‡å¥½çš„Campaignå¯¹è±¡
- âœ… æ— éœ€é‡æ–°å¤„ç†SMILESæˆ–æè¿°ç¬¦
- âœ… ä¸“æ³¨äºæ¨èç­–ç•¥å’Œå®éªŒè®¾è®¡

#### è¾“å…¥å‚æ•°
```python
input_params = {
    "baybe_campaign": Campaign,       # æ¥è‡ªSearchSpace Construction Agentçš„å®Œæ•´Campaign
    "historical_data": pd.DataFrame,  # å†å²å®éªŒæ•°æ®ï¼ˆå¯é€‰ï¼‰
    "recommendation_config": {
        "batch_size": int,
        "acquisition_function": str,  # "qEI" | "qNEI" | "qPI" | "qUCB"
        "optimization_strategy": str  # "SINGLE" | "DESIRABILITY" | "PARETO"
    },
    "experimental_results": pd.DataFrame,    # ç”¨æˆ·ä¸Šä¼ çš„å®éªŒç»“æœï¼ˆå¯é€‰ï¼‰
    "iteration_mode": str                    # "INITIAL" | "UPDATE" | "CONVERGENCE_CHECK"
}
```

#### è¾“å‡ºå‚æ•°
```python
output_params = {
    "baybe_campaign": Campaign,  # BayBE Campaignå¯¹è±¡
    "recommendations": pd.DataFrame,  # æ¨èçš„å®éªŒæ¡ä»¶
    "acquisition_values": [],  # è·å–å‡½æ•°å€¼
    "uncertainty_estimates": [],  # ä¸ç¡®å®šæ€§ä¼°è®¡
    "optimization_progress": {
        "current_best": dict,
        "improvement_rate": float,
        "convergence_status": str,
        "pareto_frontier": pd.DataFrame  # ä»…å¤šç›®æ ‡ä¼˜åŒ–
    },
    "model_diagnostics": {
        "gp_hyperparameters": dict,
        "model_likelihood": float,
        "prediction_variance": []
    }
}
```

#### å®éªŒç»“æœå›ä¼ æœºåˆ¶è®¾è®¡

**2. æ ‡å‡†åŒ–å®éªŒç»“æœä¸Šä¼ æ¥å£**:
```python
class ExperimentalResultsHandler:
    """
    å¤„ç†ç”¨æˆ·å®éªŒç»“æœå›ä¼ çš„æ ‡å‡†åŒ–æ¥å£
    """
    
    def validate_experimental_results(self, results: pd.DataFrame, campaign: Campaign) -> dict:
        """
        éªŒè¯å®éªŒç»“æœçš„å®Œæ•´æ€§å’Œæ ¼å¼
        """
        validation_report = {
            "is_valid": True,
            "missing_columns": [],
            "data_issues": [],
            "recommendations": []
        }
        
        # 1. æ£€æŸ¥å¿…éœ€çš„ç›®æ ‡åˆ—
        expected_targets = [target.name for target in campaign.objective.targets]
        missing_targets = [col for col in expected_targets if col not in results.columns]
        
        if missing_targets:
            validation_report["missing_columns"].extend(missing_targets)
            validation_report["is_valid"] = False
        
        # 2. æ£€æŸ¥å‚æ•°åˆ—åŒ¹é…
        expected_params = campaign.searchspace.parameter_names
        missing_params = [col for col in expected_params if col not in results.columns]
        
        if missing_params:
            validation_report["missing_columns"].extend(missing_params)
            validation_report["is_valid"] = False
        
        # 3. æ•°å€¼èŒƒå›´éªŒè¯
        for target in expected_targets:
            if target in results.columns:
                target_obj = next(t for t in campaign.objective.targets if t.name == target)
                if target_obj.bounds:
                    out_of_bounds = results[
                        (results[target] < target_obj.bounds[0]) | 
                        (results[target] > target_obj.bounds[1])
                    ]
                    if not out_of_bounds.empty:
                        validation_report["data_issues"].append({
                            "issue": f"{target} è¶…å‡ºé¢„æœŸèŒƒå›´ {target_obj.bounds}",
                            "affected_rows": out_of_bounds.index.tolist()
                        })
        
        return validation_report
    
    def process_results_upload(self, 
                              campaign: Campaign, 
                              results_file: str,
                              user_notes: str = "") -> dict:
        """
        å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„å®éªŒç»“æœ
        
        Args:
            campaign: å½“å‰çš„BayBE Campaign
            results_file: å®éªŒç»“æœCSVæ–‡ä»¶è·¯å¾„
            user_notes: ç”¨æˆ·çš„å®éªŒå¤‡æ³¨
            
        Returns:
            dict: å¤„ç†ç»“æœå’Œæ›´æ–°åçš„Campaignä¿¡æ¯
        """
        try:
            # 1. è¯»å–å®éªŒç»“æœ
            results_df = pd.read_csv(results_file)
            
            # 2. éªŒè¯æ•°æ®æ ¼å¼
            validation = self.validate_experimental_results(results_df, campaign)
            
            if not validation["is_valid"]:
                return {
                    "success": False,
                    "validation_errors": validation,
                    "suggested_format": self._generate_template(campaign)
                }
            
            # 3. æ•°æ®é¢„å¤„ç†
            processed_results = self._preprocess_results(results_df, campaign)
            
            # 4. æ›´æ–°BayBE Campaign
            campaign.add_measurements(processed_results)
            
            # 5. è®°å½•å®éªŒå…ƒä¿¡æ¯
            experiment_metadata = {
                "upload_timestamp": datetime.now().isoformat(),
                "user_notes": user_notes,
                "experiment_count": len(processed_results),
                "targets_measured": list(processed_results.columns[processed_results.columns.isin(
                    [t.name for t in campaign.objective.targets]
                )])
            }
            
            return {
                "success": True,
                "updated_campaign": campaign,
                "experiment_metadata": experiment_metadata,
                "ready_for_next_iteration": True
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "suggested_actions": [
                    "æ£€æŸ¥CSVæ–‡ä»¶æ ¼å¼",
                    "ç¡®è®¤ç›®æ ‡åˆ—åç§°åŒ¹é…",
                    "éªŒè¯æ•°å€¼èŒƒå›´åˆç†æ€§"
                ]
            }
    
    def _generate_template(self, campaign: Campaign) -> pd.DataFrame:
        """
        ç”Ÿæˆæ ‡å‡†çš„å®éªŒç»“æœä¸Šä¼ æ¨¡æ¿
        """
        template_data = {}
        
        # æ·»åŠ æ‰€æœ‰å‚æ•°åˆ—
        for param_name in campaign.searchspace.parameter_names:
            template_data[param_name] = ["ç¤ºä¾‹å€¼1", "ç¤ºä¾‹å€¼2"]
            
        # æ·»åŠ æ‰€æœ‰ç›®æ ‡åˆ—
        for target in campaign.objective.targets:
            template_data[target.name] = [0.0, 0.0]  # å ä½ç¬¦å€¼
            
        # æ·»åŠ å¯é€‰çš„å…ƒæ•°æ®åˆ—
        template_data["experiment_id"] = ["EXP_001", "EXP_002"]
        template_data["experiment_date"] = ["2025-01-01", "2025-01-02"] 
        template_data["user_notes"] = ["å¤‡æ³¨1", "å¤‡æ³¨2"]
        
        return pd.DataFrame(template_data)

# ä½¿ç”¨ç¤ºä¾‹
def experimental_workflow_example():
    """
    å®Œæ•´çš„å®éªŒ-åé¦ˆ-ä¼˜åŒ–å¾ªç¯ç¤ºä¾‹
    """
    
    # 1. è·å–åˆå§‹æ¨è
    recommendations = campaign.recommend(batch_size=5)
    
    # 2. ç”¨æˆ·è¿›è¡Œå®éªŒï¼ˆç¦»çº¿ï¼‰
    print("è¯·æŒ‰ç…§ä»¥ä¸‹æ¡ä»¶è¿›è¡Œå®éªŒï¼š")
    print(recommendations)
    
    # 3. ç”¨æˆ·ä¸Šä¼ ç»“æœ
    results_handler = ExperimentalResultsHandler()
    upload_result = results_handler.process_results_upload(
        campaign=campaign,
        results_file="user_experiment_results.csv",
        user_notes="ç¬¬ä¸€è½®å®éªŒï¼Œååº”æ¸©åº¦ç¨é«˜"
    )
    
    if upload_result["success"]:
        # 4. è·å–ä¸‹ä¸€è½®æ¨è
        updated_campaign = upload_result["updated_campaign"]
        next_recommendations = updated_campaign.recommend(batch_size=5)
        
        print("å®éªŒç»“æœå·²æˆåŠŸæ·»åŠ ï¼Œä¸‹ä¸€è½®æ¨èï¼š")
        print(next_recommendations)
    else:
        print("ç»“æœä¸Šä¼ å¤±è´¥ï¼š", upload_result["validation_errors"])
```

### 4. Fitting Agent (æ¨¡å‹åˆ†æä¸å¯è§†åŒ–æ™ºèƒ½ä½“)

#### ä¸»è¦ä»»åŠ¡
1. **BayBEæ¨¡å‹åˆ†æ**: åˆ©ç”¨BayBEå†…ç½®çš„æ€§èƒ½è¯„ä¼°å’Œæ¨¡å‹è¯Šæ–­
2. **ä»£ç†æ¨¡å‹è§£é‡Š**: è®­ç»ƒè§£é‡Šæ€§æ¨¡å‹è¾…åŠ©ç†è§£ä¼˜åŒ–è¿‡ç¨‹  
3. **æ”¶æ•›æ€§åˆ†æ**: ç›‘æ§ä¼˜åŒ–æ”¶æ•›æ€§å’Œæä¾›åœæ­¢å»ºè®®
4. **å®éªŒè®¾è®¡åˆ†æ**: è¯„ä¼°å·²å®Œæˆå®éªŒçš„è®¾è®¡è´¨é‡
5. **ç»“æœå¯è§†åŒ–**: ç”Ÿæˆä¼˜åŒ–è¿‡ç¨‹å’Œç»“æœçš„ä¸“ä¸šå›¾è¡¨
6. **ç»¼åˆæŠ¥å‘Š**: åˆ›å»ºåŒ…å«insightsçš„optimizationæŠ¥å‘Š

#### å®ç°ç›®æ ‡
- åˆ©ç”¨BayBEå†…ç½®çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°èƒ½åŠ›
- æä¾›ä¼˜åŒ–è¿‡ç¨‹çš„æ·±åº¦è§£é‡Š (å¯è§£é‡Šæ€§ > 85%)
- ç”Ÿæˆpublication-readyçš„å¯è§†åŒ–å›¾è¡¨
- æ”¯æŒå®éªŒå†³ç­–å’Œç­–ç•¥è°ƒæ•´
- å®ç°æ”¶æ•›æ£€æµ‹å’Œå®éªŒåœæ­¢å»ºè®®

#### ğŸ”‘ **Fitting AgentåŠŸèƒ½å®šä½è¯´æ˜**

**ä¸æ˜¯ä½¿ç”¨BayBEçš„backteståŠŸèƒ½**ï¼Œè€Œæ˜¯ï¼š
- âœ… **å®æ—¶åˆ†æ**: åˆ†æå½“å‰Campaignçš„æ€§èƒ½å’ŒçŠ¶æ€
- âœ… **æ¨¡å‹è§£é‡Š**: åˆ›å»ºå¯è§£é‡Šçš„ä»£ç†æ¨¡å‹
- âœ… **ä¼˜åŒ–æ´å¯Ÿ**: æä¾›ä¼˜åŒ–ç­–ç•¥å»ºè®®
- âœ… **å®éªŒæŒ‡å¯¼**: ååŠ©ç”¨æˆ·ç†è§£å®éªŒç»“æœ

**BayBE Backtest vs Fitting Agent**:
- **Backtest**: ç”¨äºç®—æ³•å¼€å‘é˜¶æ®µçš„æ€§èƒ½è¯„ä¼°
- **Fitting Agent**: ç”¨äºå®é™…å®éªŒé˜¶æ®µçš„å®æ—¶åˆ†æå’ŒæŒ‡å¯¼

#### è¾“å…¥å‚æ•°
```python
input_params = {
    "baybe_campaign": Campaign,
    "optimization_results": dict,
    "processed_data": pd.DataFrame,
    "visualization_config": {
        "plot_types": [],  # ["pareto", "convergence", "feature_importance"]
        "save_format": str,  # "png" | "svg" | "pdf"
        "dpi": int
    }
}
```

#### è¾“å‡ºå‚æ•°
```python
output_params = {
    "performance_metrics": {
        "r2_score": float,
        "rmse": float,
        "mae": float,
        "cross_validation_score": float
    },
    "visualization_files": {
        "convergence_plot": str,      # æ”¶æ•›æ›²çº¿å›¾è·¯å¾„
        "pareto_front_plot": str,     # å¸•ç´¯æ‰˜å‰æ²¿å›¾è·¯å¾„
        "feature_importance_plot": str, # ç‰¹å¾é‡è¦æ€§å›¾è·¯å¾„
        "predicted_vs_actual_plot": str  # é¢„æµ‹vså®é™…å›¾è·¯å¾„
    },
    "optimization_report": {
        "summary": str,
        "best_conditions": dict,
        "improvement_achieved": float,
        "recommendations": [],
        "statistical_significance": dict
    },
    "model_artifacts": {
        "trained_model": object,      # è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹è±¡
        "feature_names": [],
        "model_interpretation": dict
    }
}
```

---

## å‚æ•°ä¼ é€’ä½“ç³»

### æç®€åŒ–å‚æ•°æµè½¬å›¾

```
User Upload â†’ Enhanced Verification Agent
    â†“ (validated_data + SMILES, baybe_campaign_config, quality_report)
SearchSpace Construction Agent  
    â†“ (ready_baybe_campaign)
Recommender Agent
    â†“ (recommendations, updated_campaign, progress)
Fitting Agent
    â†“ (performance_metrics, visualizations, reports)
User Feedback
```

**ğŸš€ å…³é”®æ¶æ„çªç ´**: åŸºäºBayBEè‡ªåŠ¨æè¿°ç¬¦å¤„ç†èƒ½åŠ›ï¼Œå®ç°æç®€åŒ–æµç¨‹ï¼š

1. **æ— æè¿°ç¬¦ä¼ é€’**: åªä¼ é€’åŸå§‹SMILESï¼ŒBayBEå†…éƒ¨è‡ªåŠ¨å¤„ç†
2. **å³ç”¨å‹Campaign**: SearchSpace Agentç›´æ¥è¾“å‡ºå¯ç”¨çš„Campaign
3. **æœ€å°åŒ–å¼€é”€**: æ˜¾è‘—å‡å°‘Agenté—´çš„æ•°æ®ä¼ é€’å’Œè®¡ç®—è´Ÿæ‹…
4. **ä¸“ä¸šåŒ–åˆ†å·¥**: æ¯ä¸ªAgentä¸“æ³¨äºå…¶æ ¸å¿ƒä»·å€¼ï¼ˆéªŒè¯ã€æ„å»ºã€æ¨èã€åˆ†æï¼‰

**é‡è¦è¯´æ˜**: BayBEå…·æœ‰è‡ªåŠ¨åˆ†å­æè¿°ç¬¦è®¡ç®—å’Œä¼˜åŒ–èƒ½åŠ›ã€‚ç³»ç»Ÿ**å®Œå…¨ä¸è¿›è¡Œæ‰‹åŠ¨æè¿°ç¬¦è®¡ç®—ã€å­˜å‚¨æˆ–ä¼ é€’**ï¼Œè€Œæ˜¯ç›´æ¥å°†åŸå§‹SMILESä¼ é€’ç»™BayBEï¼Œè®©å…¶å†…éƒ¨è‡ªåŠ¨å¤„ç†æ‰€æœ‰åˆ†å­ç‰¹å¾å·¥ç¨‹å’Œä¼˜åŒ–ã€‚

### å…³é”®æ•°æ®ç»“æ„å®šä¹‰

#### BayBE Campaigné…ç½®æ ‡å‡†æ ¼å¼
```python
baybe_campaign_config = {
    "parameters": [
        {
            "name": "SubstanceA_ratio",
            "type": "NumericalContinuousParameter",
            "bounds": (0.1, 0.8),
            "tolerance": 0.01
        },
        {
            "name": "SubstanceA_molecule", 
            "type": "CategoricalParameter",
            "values": [
                "CC(C)(C1=CC=C(C=C1)OCC2CO2)C3=CC=C(C=C3)OCC4CO4",  # å—äºš127e SMILES
                "NCCCCCN"  # å…¶ä»–å‚¬åŒ–å‰‚ SMILES
            ],
            "encoding": "OHE"  # BayBEå†…éƒ¨è‡ªåŠ¨å¤„ç†åˆ†å­æè¿°ç¬¦
        }
    ],
    "targets": [  # æ— æƒé‡ï¼Œæƒé‡åœ¨DesirabilityObjectiveä¸­ç»Ÿä¸€ç®¡ç†
        {
            "name": "Target_alpha_tg",
            "mode": "MAX",
            "bounds": (60, 100),
            "transformation": "LINEAR"
        },
        {
            "name": "Target_beta_impactstrength",
            "mode": "MAX", 
            "bounds": (80, 150),
            "transformation": "LINEAR"
        }
    ],
    "objective_config": {
        "type": "DesirabilityObjective",
        "weights": [0.6, 0.4],  # å¤šç›®æ ‡æƒé‡åœ¨æ­¤ç»Ÿä¸€è®¾ç½®
        "scalarizer": "GEOM_MEAN"
    },
    "constraints": [
        {
            "type": "ContinuousLinearConstraint",  # BayBEæ ‡å‡†çº¦æŸ
            "parameters": ["SubstanceA_ratio", "SubstanceB_ratio"],
            "coefficients": [1.0, 1.0],
            "rhs": 1.0,
            "operator": "="
        }
    ],
    "experimental_config": {
        "batch_size": 5,
        "recommender": "TwoPhaseMetaRecommender"
    }
}

# ğŸ”§ æ ¸å¿ƒç†å¿µï¼šåªæä¾›SMILESï¼Œè®©BayBEè‡ªåŠ¨å¤„ç†æè¿°ç¬¦è®¡ç®—ï¼
```

#### å®éªŒæ•°æ®æ ‡å‡†æ ¼å¼
```python
experimental_data_schema = {
    "substance_columns": {
        "pattern": "{substance_name}_{attribute}",
        "required_attributes": ["name", "SMILE", "ratio"],
        "example": {
            "SubstanceA_name": "å—äºš127e",
            "SubstanceA_SMILE": "CC(C)(C1=CC=C(C=C1)OCC2CO2)C3=CC=C(C=C3)OCC4CO4",
            "SubstanceA_ratio": 0.6
        }
    },
    "target_columns": {
        "pattern": "Target_{target_name}",
        "data_type": "float",
        "example": {
            "Target_alpha_tg": 80.0,
            "Target_beta_impactstrength": 110.0,
            "Target_gamma_elongation": 1.4
        }
    },
    "metadata_columns": {
        "optional": ["experiment_id", "batch_id", "timestamp", "operator"],
        "example": {
            "experiment_id": "EXP_001",
            "batch_id": "BATCH_20250101",
            "timestamp": "2025-01-01T10:00:00Z"
        }
    }
}
```

#### SessionçŠ¶æ€ç®¡ç†ç»“æ„
```python
session_state_schema = {
    "session_id": str,           # å”¯ä¸€ä¼šè¯æ ‡è¯†ç¬¦
    "session_dir": str,          # ä¼šè¯æ–‡ä»¶å­˜å‚¨ç›®å½•
    "current_round": int,        # å½“å‰ä¼˜åŒ–è½®æ¬¡
    "status": str,               # å½“å‰çŠ¶æ€ "verifying" | "optimizing" | "complete"
    
    # æ•°æ®ç›¸å…³
    "original_data_path": str,
    "cleaned_data_path": str,
    "processed_data_path": str,
    
    # BayBEç›¸å…³
    "campaign_config": dict,     # BayBE Campaigné…ç½®
    "baybe_campaign": Campaign,  # BayBE Campaignå¯¹è±¡ï¼ˆåºåˆ—åŒ–å­˜å‚¨ï¼‰
    "searchspace": SearchSpace,  # BayBE SearchSpaceå¯¹è±¡
    
    # ä¼˜åŒ–è¿›å±•
    "optimization_history": [],  # å†å²ä¼˜åŒ–ç»“æœ
    "current_best": dict,        # å½“å‰æœ€ä¼˜ç»“æœ
    "convergence_metrics": dict, # æ”¶æ•›æŒ‡æ ‡
    
    # ç”¨æˆ·åå¥½
    "user_preferences": dict,    # ç”¨æˆ·è®¾ç½®çš„ä¼˜åŒ–åå¥½
    "interaction_log": [],       # ç”¨æˆ·äº¤äº’è®°å½•
    
    # æ–‡ä»¶è·¯å¾„
    "visualization_files": {},   # ç”Ÿæˆçš„å›¾è¡¨æ–‡ä»¶è·¯å¾„
    "report_files": {},          # ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
}
```

---

## å¼€å‘ç¯å¢ƒé…ç½®

### ç³»ç»Ÿè¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Pythonç‰ˆæœ¬**: 3.8 - 3.11 (æ¨è 3.10)
- **å†…å­˜**: æœ€ä½ 8GB RAM (æ¨è 16GB+)
- **å­˜å‚¨**: æœ€ä½ 10GB å¯ç”¨ç©ºé—´

### æ ¸å¿ƒä¾èµ–åŒ… (`requirements.txt`)
```
# æ ¸å¿ƒæ¡†æ¶
baybe>=0.11.0
google-adk>=1.0.0

# ç§‘å­¦è®¡ç®—
pandas>=1.5.0
numpy>=1.21.0
scipy>=1.9.0

# åŒ–å­¦ä¿¡æ¯å­¦
rdkit>=2023.9.1
mordred>=1.2.0

# æœºå™¨å­¦ä¹ 
scikit-learn>=1.3.0
torch>=2.0.0
botorch>=0.9.0
gpytorch>=1.11.0

# å¯è§†åŒ–
matplotlib>=3.6.0
seaborn>=0.12.0
plotly>=5.17.0

# å·¥å…·åº“
pydantic>=2.0.0
tenacity>=8.2.0
tqdm>=4.65.0
```

### ç¯å¢ƒé…ç½®æ­¥éª¤

#### 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
python -m venv chembonas_env
source chembonas_env/bin/activate  # Linux/macOS
# æˆ–
chembonas_env\Scripts\activate     # Windows
```

#### 2. å®‰è£…ä¾èµ–
```bash
pip install --upgrade pip
pip install -r agent_zyf/requirements.txt
```

#### 3. éªŒè¯å®‰è£…
```python
# è¿è¡ŒéªŒè¯è„šæœ¬
python -c "
import baybe
import rdkit
import torch
print(f'BayBE: {baybe.__version__}')
print(f'RDKit: {rdkit.__version__}')
print(f'PyTorch: {torch.__version__}')
print('All dependencies installed successfully!')
"
```

#### 4. é…ç½®ç¯å¢ƒå˜é‡
åˆ›å»º `.env` æ–‡ä»¶ï¼š
```
# Google ADKé…ç½®
GOOGLE_API_KEY=æ‚¨çš„Google_APIå¯†é’¥
GOOGLE_GENAI_USE_VERTEXAI=FALSE

# BayBEé…ç½®
BAYBE_DEFAULT_ACQUISITION=qEI
BAYBE_DEFAULT_SCALARIZER=GEOM_MEAN
BAYBE_RANDOM_SEED=42

# æ€§èƒ½é…ç½®
TORCH_NUM_THREADS=4
OMP_NUM_THREADS=4
RDKIT_NUM_THREADS=4

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
LOG_FILE=logs/chembonas.log
```

---

## æŠ€æœ¯æ ˆ

### æ ¸å¿ƒæ¡†æ¶
- **Google ADK**: æ™ºèƒ½ä½“æ¡†æ¶å’ŒLLMé›†æˆ
- **BayBE**: è´å¶æ–¯ä¼˜åŒ–å¼•æ“ (å†…ç½®ç‰¹å¾å¤„ç†å’Œæè¿°ç¬¦ä¼˜åŒ–)
- **PyTorch/BoTorch**: æ·±åº¦å­¦ä¹ å’Œè´å¶æ–¯ä¼˜åŒ–åç«¯

### åŒ–å­¦ä¿¡æ¯å­¦
- **RDKit**: åˆ†å­å¤„ç†å’ŒåŸºç¡€æè¿°ç¬¦
- **Mordred**: å¤§è§„æ¨¡åˆ†å­æè¿°ç¬¦è®¡ç®—
- **ChemProp**: å›¾ç¥ç»ç½‘ç»œåˆ†å­ç‰¹å¾ï¼ˆå¯é€‰ï¼‰

### æœºå™¨å­¦ä¹ 
- **scikit-learn**: ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•
- **GPyTorch**: é«˜æ–¯è¿‡ç¨‹å»ºæ¨¡
- **Optuna**: è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

### æ•°æ®å¤„ç†
- **pandas**: æ•°æ®å¤„ç†å’Œåˆ†æ
- **numpy**: æ•°å€¼è®¡ç®—
- **scipy**: ç§‘å­¦è®¡ç®—

### å¯è§†åŒ–
- **matplotlib**: åŸºç¡€ç»˜å›¾
- **seaborn**: ç»Ÿè®¡å¯è§†åŒ–
- **plotly**: äº¤äº’å¼å›¾è¡¨

### å¼€å‘å·¥å…·
- **pytest**: å•å…ƒæµ‹è¯•
- **black**: ä»£ç æ ¼å¼åŒ–
- **isort**: importæ’åº
- **mypy**: é™æ€ç±»å‹æ£€æŸ¥
- **pre-commit**: Git hooks

---

## éƒ¨ç½²è¯´æ˜

### æœ¬åœ°å¼€å‘éƒ¨ç½²

#### 1. é¡¹ç›®ç»“æ„
```
ChemBoMAS/
â”œâ”€â”€ agent_zyf/                    # ä¸»æ™ºèƒ½ä½“æ¨¡å—
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py                  # ä¸»åè°ƒå™¨
â”‚   â”œâ”€â”€ tools.py                  # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ prompts.py               # æç¤ºæ¨¡æ¿
â”‚   â”œâ”€â”€ sub_agents/              # å­æ™ºèƒ½ä½“
â”‚   â”‚   â”œâ”€â”€ verification/
â”‚   â”‚   â”œâ”€â”€ descriptor_optimization/
â”‚   â”‚   â”œâ”€â”€ fitting/
â”‚   â”‚   â””â”€â”€ recommender/
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ tests/                       # æµ‹è¯•æ¨¡å—
â”œâ”€â”€ docs/                        # æ–‡æ¡£
â”œâ”€â”€ logs/                        # æ—¥å¿—æ–‡ä»¶
â”œâ”€â”€ sessions/                    # ä¼šè¯æ•°æ®
â”œâ”€â”€ .env                         # ç¯å¢ƒå˜é‡
â””â”€â”€ README.md
```

#### 2. å¯åŠ¨å‘½ä»¤
```bash
# å¼€å‘æ¨¡å¼å¯åŠ¨
adk run agent_zyf --dev

# ç”Ÿäº§æ¨¡å¼å¯åŠ¨
adk run agent_zyf --port 8000

# æŒ‡å®šé…ç½®æ–‡ä»¶å¯åŠ¨
adk run agent_zyf --config config/production.yaml
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### Dockeréƒ¨ç½²
```dockerfile
FROM python:3.10-slim

WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    build-essential \
    librdkit-dev \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶å¹¶å®‰è£…Pythonä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY agent_zyf/ ./agent_zyf/
COPY .env .

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p logs sessions

EXPOSE 8000

CMD ["adk", "run", "agent_zyf", "--port", "8000"]
```

#### è¿è¡Œå®¹å™¨
```bash
# æ„å»ºé•œåƒ
docker build -t chembonas:latest .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name chembonas \
  -p 8000:8000 \
  -v $(pwd)/sessions:/app/sessions \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  chembonas:latest
```

### æ€§èƒ½ä¼˜åŒ–é…ç½®

#### 1. è®¡ç®—èµ„æºä¼˜åŒ–
```python
# é…ç½®æ–‡ä»¶ config/performance.yaml
computation:
  torch_threads: 4
  rdkit_parallel_jobs: -1  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
  baybe_batch_size: 10
  gp_max_training_iter: 100

memory:
  descriptor_cache_size: 1000  # ç¼“å­˜æè¿°ç¬¦æ•°é‡
  session_cleanup_interval: 3600  # ç§’
  max_session_age: 86400  # ç§’
```

#### 2. æ•°æ®åº“é…ç½®ï¼ˆå¯é€‰ï¼‰
```python
# ä½¿ç”¨SQLiteä½œä¸ºä¼šè¯å­˜å‚¨
database:
  type: "sqlite"
  path: "data/chembonas.db"
  pool_size: 10
  echo: false

# æˆ–ä½¿ç”¨PostgreSQLï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èï¼‰
database:
  type: "postgresql"
  host: "localhost"
  port: 5432
  database: "chembonas"
  username: "chembonas_user"
  password: "${DB_PASSWORD}"
```

### ç›‘æ§å’Œæ—¥å¿—

#### 1. æ—¥å¿—é…ç½®
```python
logging:
  version: 1
  formatters:
    standard:
      format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  handlers:
    console:
      class: logging.StreamHandler
      level: INFO
      formatter: standard
    file:
      class: logging.FileHandler
      level: DEBUG
      formatter: standard
      filename: logs/chembonas.log
  loggers:
    chembonas:
      level: INFO
      handlers: [console, file]
    baybe:
      level: WARNING
      handlers: [file]
```

#### 2. æ€§èƒ½ç›‘æ§
```python
# å†…ç½®æ€§èƒ½æŒ‡æ ‡
metrics:
  - optimization_convergence_time
  - descriptor_calculation_time
  - recommendation_generation_time
  - user_interaction_response_time
  - memory_usage
  - session_count
```

### å®‰å…¨é…ç½®

#### 1. APIå¯†é’¥ç®¡ç†
```bash
# ä½¿ç”¨å¯†é’¥ç®¡ç†æœåŠ¡
export GOOGLE_API_KEY=$(vault kv get -field=api_key secret/google)

# æˆ–ä½¿ç”¨ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆå¼€å‘ç¯å¢ƒï¼‰
echo "GOOGLE_API_KEY=your_key_here" > .env.local
```

#### 2. æ•°æ®å®‰å…¨
```python
# æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨
encryption:
  algorithm: "AES-256-GCM"
  key_derivation: "PBKDF2"
  salt_length: 32
  
# ç”¨æˆ·æ•°æ®éšç§
privacy:
  anonymize_data: true
  data_retention_days: 90
  audit_log_enabled: true
```

---

## å¼€å‘æœ€ä½³å®è·µ

### ä»£ç è´¨é‡
1. **ç±»å‹æç¤º**: æ‰€æœ‰å‡½æ•°å¿…é¡»æœ‰å®Œæ•´çš„ç±»å‹æç¤º
2. **æ–‡æ¡£å­—ç¬¦ä¸²**: ä½¿ç”¨Googleé£æ ¼çš„docstring
3. **é”™è¯¯å¤„ç†**: ä½¿ç”¨ç»“æ„åŒ–å¼‚å¸¸å¤„ç†
4. **æµ‹è¯•è¦†ç›–**: å•å…ƒæµ‹è¯•è¦†ç›–ç‡ > 80%

### æ€§èƒ½ä¼˜åŒ–
1. **å¼‚æ­¥å¤„ç†**: ä½¿ç”¨async/awaitå¤„ç†IOå¯†é›†å‹æ“ä½œ
2. **ç¼“å­˜ç­–ç•¥**: ç¼“å­˜è®¡ç®—ç»“æœå’Œæ¨¡å‹é¢„æµ‹
3. **æ‰¹å¤„ç†**: æ‰¹é‡å¤„ç†åˆ†å­æè¿°ç¬¦è®¡ç®—
4. **å†…å­˜ç®¡ç†**: åŠæ—¶é‡Šæ”¾å¤§å‹å¯¹è±¡

### å®‰å…¨è€ƒè™‘
1. **è¾“å…¥éªŒè¯**: ä¸¥æ ¼éªŒè¯æ‰€æœ‰ç”¨æˆ·è¾“å…¥
2. **æƒé™æ§åˆ¶**: å®ç°åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶
3. **å®¡è®¡æ—¥å¿—**: è®°å½•æ‰€æœ‰é‡è¦æ“ä½œ
4. **æ•°æ®åŠ å¯†**: æ•æ„Ÿæ•°æ®åŠ å¯†å­˜å‚¨

---

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. BayBEå®‰è£…å¤±è´¥
```bash
# è§£å†³æ–¹æ¡ˆï¼šç¡®ä¿PyTorchç‰ˆæœ¬å…¼å®¹
pip install torch==2.0.1 --index-url https://download.pytorch.org/whl/cpu
pip install baybe
```

#### 2. RDKitå¯¼å…¥é”™è¯¯
```bash
# è§£å†³æ–¹æ¡ˆï¼šé‡æ–°å®‰è£…RDKit
conda install -c conda-forge rdkit
# æˆ–
pip install rdkit
```

#### 3. å†…å­˜ä¸è¶³é”™è¯¯
```python
# è§£å†³æ–¹æ¡ˆï¼šä¼˜åŒ–é…ç½®
BAYBE_MAX_PARALLEL_JOBS=2
TORCH_NUM_THREADS=2
DESCRIPTOR_BATCH_SIZE=100
```

### è°ƒè¯•å·¥å…·
```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG

# æ€§èƒ½åˆ†æ
python -m cProfile -o profile.stats main.py

# å†…å­˜åˆ†æ
python -m memory_profiler main.py
```

---

## åŸºäºç»éªŒçš„æ¶æ„ä¸ç®—æ³•å»ºè®®

### ğŸ›ï¸ æ¶æ„è®¾è®¡æœ€ä½³å®è·µ

#### 1. **å‚è€ƒç±»ä¼¼é¡¹ç›®ç»éªŒ**

**æˆåŠŸæ¡ˆä¾‹åˆ†æ**:
- **ChemTS**: åˆ†å­ç”Ÿæˆä¸­çš„è’™ç‰¹å¡æ´›æ ‘æœç´¢ + RNNæ¶æ„
- **ML4Chem**: åŒ–å­¦æœºå™¨å­¦ä¹ çš„å®Œæ•´æµç¨‹è®¾è®¡
- **Auto-RL**: è‡ªåŠ¨åŒ–å¼ºåŒ–å­¦ä¹ ä¸­çš„å¤šæ™ºèƒ½ä½“åè°ƒ
- **OptBayesExpt**: è´å¶æ–¯å®éªŒè®¾è®¡çš„å·¥ä¸šåº”ç”¨

**æ ¸å¿ƒç»éªŒæ•™è®­**:
```python
# 1. åˆ†å±‚è´£ä»»åŸåˆ™
class ArchitecturePatterns:
    """
    åŸºäºæˆåŠŸé¡¹ç›®çš„æ¶æ„æ¨¡å¼
    """
    SEPARATION_OF_CONCERNS = {
        "æ•°æ®å±‚": "åªè´Ÿè´£æ•°æ®éªŒè¯å’Œæ ‡å‡†åŒ–",
        "é€»è¾‘å±‚": "ä¸šåŠ¡é€»è¾‘å’Œç”¨æˆ·äº¤äº’", 
        "ç®—æ³•å±‚": "çº¯ç®—æ³•æ‰§è¡Œï¼ˆæ— ç”¨æˆ·äº¤äº’ï¼‰",
        "å±•ç¤ºå±‚": "ç»“æœåˆ†æå’Œå¯è§†åŒ–"
    }
    
    SCALABILITY_PATTERNS = {
        "å¼‚æ­¥å¤„ç†": "é•¿æ—¶é—´è®¡ç®—ä½¿ç”¨åå°ä»»åŠ¡",
        "çŠ¶æ€ç®¡ç†": "æ¸…æ™°çš„ä¼šè¯çŠ¶æ€å’Œæ¢å¤æœºåˆ¶",
        "é”™è¯¯æ¢å¤": "graceful degradationå’Œè‡ªåŠ¨é‡è¯•",
        "èµ„æºç®¡ç†": "å†…å­˜å’Œè®¡ç®—èµ„æºçš„æ™ºèƒ½åˆ†é…"
    }
```

#### 2. **ChemBoMASæ¶æ„ä¼˜åŠ¿åˆ†æ**

**æˆ‘ä»¬çš„è®¾è®¡ä¼˜åŠ¿**:
- âœ… **ä¸“ä¸šåŒ–Agent**: æ¯ä¸ªAgentæœ‰æ˜ç¡®çš„åŒ–å­¦/ä¼˜åŒ–ä¸“ä¸šèŒè´£
- âœ… **BayBEåŸç”Ÿé›†æˆ**: é¿å…äº†ç‰¹å¾å·¥ç¨‹çš„å¤æ‚æ€§
- âœ… **ç”¨æˆ·ä¸­å¿ƒè®¾è®¡**: å¼ºè°ƒç”¨æˆ·äº¤äº’å’Œå®éªŒæŒ‡å¯¼
- âœ… **æ¨¡å—åŒ–æ‰©å±•**: æ˜“äºæ·»åŠ æ–°çš„ä¼˜åŒ–ç­–ç•¥æˆ–åˆ†æåŠŸèƒ½

**ä¸ç±»ä¼¼é¡¹ç›®çš„å·®å¼‚åŒ–**:
```python
comparison_analysis = {
    "ChemTS": {
        "ä¼˜åŠ¿": "ä¸“æ³¨åˆ†å­ç”Ÿæˆ",
        "å±€é™": "ç¼ºä¹å®éªŒä¼˜åŒ–é—­ç¯",
        "æˆ‘ä»¬çš„æ”¹è¿›": "å®Œæ•´çš„å®éªŒ-åé¦ˆ-ä¼˜åŒ–å¾ªç¯"
    },
    "ML4Chem": {
        "ä¼˜åŠ¿": "å®Œæ•´çš„æœºå™¨å­¦ä¹ æµç¨‹",
        "å±€é™": "ç¼ºä¹æ™ºèƒ½ä½“åè°ƒå’Œç”¨æˆ·äº¤äº’",
        "æˆ‘ä»¬çš„æ”¹è¿›": "å¤šæ™ºèƒ½ä½“åè°ƒå’Œå®æ—¶ç”¨æˆ·æŒ‡å¯¼"
    },
    "ä¼ ç»ŸBOå·¥å…·": {
        "ä¼˜åŠ¿": "ç®—æ³•æˆç†Ÿ",
        "å±€é™": "éœ€è¦å¤§é‡æ‰‹åŠ¨ç‰¹å¾å·¥ç¨‹",
        "æˆ‘ä»¬çš„æ”¹è¿›": "BayBEè‡ªåŠ¨åŒ– + LLMæ™ºèƒ½å»ºè®®"
    }
}
```

### ğŸ§® ç®—æ³•å®ç°å»ºè®®

#### 1. **è´å¶æ–¯ä¼˜åŒ–ç­–ç•¥**

**å¤šç›®æ ‡ä¼˜åŒ–ç­–ç•¥é€‰æ‹©**:
```python
optimization_strategies = {
    "æ¢ç´¢é˜¶æ®µ": {
        "acquisition_function": "qEI",  # Expected Improvement
        "batch_size": 3-5,
        "strategy": "space_filling",
        "é€‚ç”¨åœºæ™¯": "åˆæœŸå®éªŒï¼Œéœ€è¦å¹¿æ³›æ¢ç´¢"
    },
    "åˆ©ç”¨é˜¶æ®µ": {
        "acquisition_function": "qUCB",  # Upper Confidence Bound  
        "batch_size": 2-3,
        "strategy": "exploitation",
        "é€‚ç”¨åœºæ™¯": "æ‰¾åˆ°æœ‰å¸Œæœ›åŒºåŸŸåçš„ç²¾ç»†ä¼˜åŒ–"
    },
    "å¤šç›®æ ‡å¹³è¡¡": {
        "acquisition_function": "qNEHVI",  # Noisy Expected HyperVolume Improvement
        "objective_type": "ParetoObjective",
        "strategy": "pareto_frontier",
        "é€‚ç”¨åœºæ™¯": "å¤šä¸ªå†²çªç›®æ ‡çš„å¹³è¡¡ä¼˜åŒ–"
    }
}
```

#### 2. **è‡ªé€‚åº”å®éªŒè®¾è®¡**

**åŸºäºå®éªŒè¿›å±•çš„åŠ¨æ€è°ƒæ•´**:
```python
class AdaptiveExperimentDesign:
    """
    è‡ªé€‚åº”å®éªŒè®¾è®¡ç­–ç•¥
    """
    
    def adjust_strategy_based_on_progress(self, campaign: Campaign, iteration: int) -> dict:
        """
        æ ¹æ®ä¼˜åŒ–è¿›å±•åŠ¨æ€è°ƒæ•´ç­–ç•¥
        """
        progress_analysis = self._analyze_optimization_progress(campaign)
        
        strategy_adjustments = {}
        
        if iteration < 3:
            # åˆæœŸï¼šæ¢ç´¢ä¸ºä¸»
            strategy_adjustments = {
                "acquisition_function": "qEI",
                "batch_size": 5,
                "focus": "exploration"
            }
        elif progress_analysis["improvement_rate"] > 0.1:
            # å¿«é€Ÿæ”¹è¿›æœŸï¼šç»§ç»­æ¢ç´¢
            strategy_adjustments = {
                "acquisition_function": "qNEI", 
                "batch_size": 4,
                "focus": "balanced"
            }
        elif progress_analysis["improvement_rate"] < 0.05:
            # æ”¶æ•›æœŸï¼šç²¾ç»†åŒ–åˆ©ç”¨
            strategy_adjustments = {
                "acquisition_function": "qUCB",
                "batch_size": 2,
                "focus": "exploitation"
            }
        
        return strategy_adjustments

    def _analyze_optimization_progress(self, campaign: Campaign) -> dict:
        """
        åˆ†æä¼˜åŒ–è¿›å±•
        """
        measurements = campaign.measurements
        
        if len(measurements) < 2:
            return {"improvement_rate": 1.0, "status": "initial"}
            
        # è®¡ç®—ç›®æ ‡å€¼çš„æ”¹è¿›è¶‹åŠ¿
        targets = [t.name for t in campaign.objective.targets]
        recent_improvements = []
        
        for target in targets:
            values = measurements[target].values
            if len(values) >= 5:
                recent_avg = np.mean(values[-3:])
                previous_avg = np.mean(values[-6:-3])
                improvement = (recent_avg - previous_avg) / abs(previous_avg) if previous_avg != 0 else 0
                recent_improvements.append(abs(improvement))
        
        avg_improvement = np.mean(recent_improvements) if recent_improvements else 0
        
        return {
            "improvement_rate": avg_improvement,
            "iterations_completed": len(measurements),
            "convergence_trend": "converging" if avg_improvement < 0.05 else "improving"
        }
```

#### 3. **å®éªŒæ•ˆç‡ä¼˜åŒ–**

**æ‰¹é‡å®éªŒè®¾è®¡ç­–ç•¥**:
```python
batch_design_strategies = {
    "parallel_experiments": {
        "description": "å¹¶è¡Œå®éªŒè®¾è®¡",
        "implementation": "qEI with batch acquisition",
        "advantages": ["å‡å°‘å®éªŒè½®æ¬¡", "æé«˜throughput"],
        "é€‚ç”¨åœºæ™¯": "æœ‰å¤šä¸ªååº”å™¨æˆ–å®éªŒå°"
    },
    "sequential_learning": {
        "description": "åºåˆ—å­¦ä¹ ",
        "implementation": "å•ç‚¹ä¼˜åŒ– + å¿«é€Ÿåé¦ˆ",
        "advantages": ["æœ€å¤§åŒ–ä¿¡æ¯å¢ç›Š", "å¿«é€Ÿæ”¶æ•›"],
        "é€‚ç”¨åœºæ™¯": "å®éªŒæˆæœ¬é«˜æˆ–æ—¶é—´æ•æ„Ÿ"
    },
    "hybrid_approach": {
        "description": "æ··åˆç­–ç•¥",
        "implementation": "åˆæœŸå¹¶è¡Œ + åæœŸåºåˆ—",
        "advantages": ["å¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨", "èµ„æºä¼˜åŒ–"],
        "é€‚ç”¨åœºæ™¯": "å¤§å¤šæ•°å®é™…åº”ç”¨"
    }
}
```

### ğŸ¯ ç³»ç»Ÿé›†æˆå»ºè®®

#### 1. **ç”¨æˆ·ä½“éªŒä¼˜åŒ–**

**æ™ºèƒ½åŒ–ç”¨æˆ·æŒ‡å¯¼**:
```python
class UserExperienceEnhancer:
    """
    åŸºäºåŒ–å­¦ä¸“ä¸šçŸ¥è¯†çš„ç”¨æˆ·ä½“éªŒä¼˜åŒ–
    """
    
    def provide_contextual_guidance(self, user_input: dict, campaign_state: dict) -> dict:
        """
        æä¾›æƒ…å¢ƒåŒ–çš„ç”¨æˆ·æŒ‡å¯¼
        """
        guidance = {
            "parameter_suggestions": [],
            "experimental_tips": [],
            "optimization_insights": [],
            "next_steps": []
        }
        
        # åŸºäºå®éªŒç±»å‹æä¾›ä¸“ä¸šå»ºè®®
        if "epoxy" in str(user_input).lower():
            guidance["experimental_tips"].extend([
                "æ³¨æ„ç¯æ°§å›ºåŒ–çš„æ”¾çƒ­ååº”",
                "æ§åˆ¶å›ºåŒ–æ¸©åº¦é¿å…è¿‡åº¦äº¤è”",
                "ç›‘æ§å‡èƒ¶æ—¶é—´ä»¥ç¡®ä¿å¯æ“ä½œæ€§"
            ])
            
        if campaign_state.get("iterations_completed", 0) > 5:
            guidance["optimization_insights"].append(
                "å·²å®Œæˆå¤šè½®ä¼˜åŒ–ï¼Œå»ºè®®å…³æ³¨Paretoå‰æ²¿çš„æƒè¡¡åŒºåŸŸ"
            )
            
        return guidance
```

#### 2. **è´¨é‡ä¿è¯ä½“ç³»**

**å¤šå±‚éªŒè¯æœºåˆ¶**:
```python
class QualityAssuranceFramework:
    """
    å¤šå±‚è´¨é‡ä¿è¯æ¡†æ¶
    """
    
    VALIDATION_LAYERS = {
        "æ•°æ®å±‚": ["SMILESæœ‰æ•ˆæ€§", "æ•°å€¼èŒƒå›´æ£€æŸ¥", "ç¼ºå¤±å€¼å¤„ç†"],
        "ç®—æ³•å±‚": ["CampaignçŠ¶æ€éªŒè¯", "æ”¶æ•›æ€§æ£€æµ‹", "æ¨¡å‹è¯Šæ–­"],
        "ç»“æœå±‚": ["æ¨èåˆç†æ€§", "åŒ–å­¦å¯è¡Œæ€§", "å®éªŒå®‰å…¨æ€§"],
        "ç”¨æˆ·å±‚": ["äº¤äº’å“åº”", "é”™è¯¯ä¿¡æ¯", "æ“ä½œæŒ‡å¯¼"]
    }
    
    def comprehensive_validation(self, system_state: dict) -> dict:
        """
        å…¨é¢çš„ç³»ç»ŸéªŒè¯
        """
        validation_results = {}
        
        for layer, checks in self.VALIDATION_LAYERS.items():
            layer_results = []
            for check in checks:
                result = self._execute_validation(check, system_state)
                layer_results.append(result)
            validation_results[layer] = layer_results
            
        return validation_results
```

### ğŸ”¬ åŒ–å­¦å®éªŒç‰¹å®šä¼˜åŒ–

#### 1. **é¢†åŸŸçŸ¥è¯†é›†æˆ**

**åŒ–å­¦çº¦æŸå’Œè§„åˆ™å¼•æ“**:
```python
class ChemicalKnowledgeEngine:
    """
    åŒ–å­¦é¢†åŸŸçŸ¥è¯†å¼•æ“
    """
    
    CHEMICAL_RULES = {
        "epoxy_curing": {
            "temperature_range": (60, 120),
            "catalyst_ratio_limits": (0.01, 0.1),
            "curing_time_factors": ["temperature", "catalyst_type", "humidity"],
            "incompatible_combinations": [
                ("å¼ºé…¸å‚¬åŒ–å‰‚", "ç¢±æ€§åŠ©å‰‚"),
                ("é«˜æ¸©æ•æ„Ÿæ·»åŠ å‰‚", "é«˜æ¸©å›ºåŒ–")
            ]
        },
        "polymerization": {
            "initiator_concentration": (0.001, 0.05),
            "temperature_control": "ä¸¥æ ¼æ§åˆ¶é¿å…æš´èš",
            "oxygen_sensitivity": "éœ€è¦æƒ°æ€§æ°”æ°›ä¿æŠ¤"
        }
    }
    
    def apply_chemical_constraints(self, parameters: list, reaction_type: str) -> list:
        """
        åº”ç”¨åŒ–å­¦çº¦æŸåˆ°BayBEå‚æ•°
        """
        rules = self.CHEMICAL_RULES.get(reaction_type, {})
        constrained_parameters = []
        
        for param in parameters:
            if hasattr(param, 'bounds') and param.name in rules:
                # åº”ç”¨åŒ–å­¦çŸ¥è¯†çº¦æŸ
                chemical_bounds = rules.get(param.name.split('_')[0] + "_range")
                if chemical_bounds:
                    param.bounds = (
                        max(param.bounds[0], chemical_bounds[0]),
                        min(param.bounds[1], chemical_bounds[1])
                    )
            constrained_parameters.append(param)
            
        return constrained_parameters
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†åŸºäºBayBEçš„ChemBoMASå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„æ¶æ„è®¾è®¡ã€å®ç°ç»†èŠ‚å’Œéƒ¨ç½²æ–¹æ¡ˆã€‚é€šè¿‡æ˜ç¡®å®šä¹‰æ¯ä¸ªæ™ºèƒ½ä½“çš„èŒè´£ã€è¾“å…¥è¾“å‡ºå‚æ•°ä»¥åŠæ•°æ®æµè½¬æœºåˆ¶ï¼Œä¸ºé¡¹ç›®çš„åç»­å¼€å‘å’Œç»´æŠ¤æä¾›äº†å®Œæ•´çš„æŠ€æœ¯æŒ‡å¯¼ã€‚

### å…³é”®ç‰¹ç‚¹
- **BayBEåŸç”Ÿé›†æˆ**: å……åˆ†åˆ©ç”¨BayBEçš„è‡ªåŠ¨åˆ†å­æè¿°ç¬¦å¤„ç†èƒ½åŠ›
- **æç®€åŒ–æ¶æ„**: 4ä¸ªä¸“ä¸šåŒ–Agentï¼Œé¿å…å†—ä½™è®¡ç®—å±‚
- **æ™ºèƒ½ç”¨æˆ·æŒ‡å¯¼**: LLMé©±åŠ¨çš„å‚æ•°å»ºè®®å’ŒåŒ–å­¦çŸ¥è¯†æ”¯æŒ
- **æ ‡å‡†åŒ–å®éªŒå¾ªç¯**: å®Œæ•´çš„æ¨è-å®éªŒ-åé¦ˆ-ä¼˜åŒ–é—­ç¯
- **è‡ªå®šä¹‰ç¼–ç æ”¯æŒ**: å¤„ç†ç‰¹æ®Šåˆ†å­ï¼ˆèšåˆç‰©ã€é«˜åˆ†å­é‡åŒ–åˆç‰©ï¼‰
- **è‡ªé€‚åº”ä¼˜åŒ–ç­–ç•¥**: åŸºäºå®éªŒè¿›å±•åŠ¨æ€è°ƒæ•´ç®—æ³•å‚æ•°
- **ç”Ÿäº§å°±ç»ª**: å®Œæ•´çš„éƒ¨ç½²ã€ç›‘æ§å’Œæ•…éšœæ’é™¤æ–¹æ¡ˆ

### æ ¸å¿ƒåˆ›æ–°ç‚¹
1. **"ç»™SMILESï¼ŒBayBEå¤„ç†ä¸€åˆ‡"**: æå¤§ç®€åŒ–äº†åˆ†å­ç‰¹å¾å·¥ç¨‹
2. **æ™ºèƒ½å‚æ•°å»ºè®®ç³»ç»Ÿ**: LLMååŠ©ç”¨æˆ·å®šä¹‰å®éªŒå‚æ•°è¾¹ç•Œ
3. **æ ‡å‡†åŒ–ç»“æœå›ä¼ **: `campaign.add_measurements()`çš„å®Œæ•´å®ç°
4. **åŒ–å­¦é¢†åŸŸçŸ¥è¯†å¼•æ“**: é›†æˆä¸“ä¸šçº¦æŸå’Œå®‰å…¨è§„åˆ™
5. **è‡ªé€‚åº”å®éªŒè®¾è®¡**: æ ¹æ®ä¼˜åŒ–è¿›å±•åŠ¨æ€è°ƒæ•´ç­–ç•¥

### ä¸‹ä¸€æ­¥å·¥ä½œ
1. æŒ‰ç…§ç®€åŒ–æ¶æ„é‡æ„ç°æœ‰Agentä»£ç 
2. å®ç°æ™ºèƒ½å‚æ•°å»ºè®®å’Œè‡ªå®šä¹‰ç¼–ç åŠŸèƒ½  
3. å¼€å‘æ ‡å‡†åŒ–çš„å®éªŒç»“æœå›ä¼ æ¥å£
4. é›†æˆåŒ–å­¦é¢†åŸŸçŸ¥è¯†å¼•æ“
5. å®Œå–„è‡ªé€‚åº”ä¼˜åŒ–ç­–ç•¥
6. å»ºç«‹å®Œæ•´çš„è´¨é‡ä¿è¯ä½“ç³»

---

## 2025å¹´1æœˆé‡å¤§æ›´æ–°

### ğŸš¨ é‡è¦ä¿®å¤å’Œæ”¹è¿›

#### 1. æ¨¡å—å¯¼å…¥é—®é¢˜ä¿®å¤ (Google ADK è§„èŒƒ)

**é—®é¢˜**: `{"error": "Fail to load 'agent_zyf' module. No module named 'sub_agents'"}`

**æ ¹æœ¬åŸå› **:
- ç¼ºå°‘å¿…è¦çš„ `__init__.py` æ–‡ä»¶
- é”™è¯¯çš„å¯¼å…¥è·¯å¾„ï¼ˆç»å¯¹å¯¼å…¥ vs ç›¸å¯¹å¯¼å…¥ï¼‰

**ä¿®å¤æªæ–½**:
```bash
# æ·»åŠ äº†ç¼ºå¤±çš„ __init__.py æ–‡ä»¶
agent_zyf/sub_agents/__init__.py
agent_zyf/sub_agents/fitting/__init__.py  
agent_zyf/sub_agents/recommender/__init__.py
agent_zyf/sub_agents/searchspace_construction/__init__.py  # å·²å­˜åœ¨
```

```python
# ä¿®å¤ agent_zyf/agent.py ä¸­çš„å¯¼å…¥è·¯å¾„
# ä»ç»å¯¹å¯¼å…¥æ”¹ä¸ºç›¸å¯¹å¯¼å…¥
from .sub_agents.searchspace_construction.agent import searchspace_construction_agent
from .sub_agents.recommender.agent import recommender_agent
from .sub_agents.fitting.agent import fitting_agent
from .prompts import return_instructions_orchestrator, return_instructions_enhanced_verification
from . import tools
from .enhanced_verification_tools import enhanced_verification, collect_optimization_goals, diagnose_data_types
```

**ç¬¦åˆGoogle ADKè§„èŒƒçš„é¡¹ç›®ç»“æ„**:
```
ChemBoMAS/
â”œâ”€â”€ agent_zyf/                  # ä¸»ä»£ç†åŒ…
â”‚   â”œâ”€â”€ __init__.py            # åŒ…æ ‡è¯†æ–‡ä»¶
â”‚   â”œâ”€â”€ agent.py               # ä¸»ç¼–æ’ä»£ç†
â”‚   â”œâ”€â”€ enhanced_verification_tools.py
â”‚   â”œâ”€â”€ tools.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â””â”€â”€ sub_agents/            # å­ä»£ç†åŒ…
â”‚       â”œâ”€â”€ __init__.py        # åŒ…æ ‡è¯†æ–‡ä»¶ âœ… æ–°å¢
â”‚       â”œâ”€â”€ fitting/
â”‚       â”‚   â”œâ”€â”€ __init__.py    # åŒ…æ ‡è¯†æ–‡ä»¶ âœ… æ–°å¢
â”‚       â”‚   â”œâ”€â”€ agent.py
â”‚       â”‚   â””â”€â”€ tools.py
â”‚       â”œâ”€â”€ recommender/
â”‚       â”‚   â”œâ”€â”€ __init__.py    # åŒ…æ ‡è¯†æ–‡ä»¶ âœ… æ–°å¢
â”‚       â”‚   â”œâ”€â”€ agent.py
â”‚       â”‚   â””â”€â”€ tools.py
â”‚       â””â”€â”€ searchspace_construction/
â”‚           â”œâ”€â”€ __init__.py    # å·²å­˜åœ¨
â”‚           â”œâ”€â”€ agent.py
â”‚           â””â”€â”€ tools.py
```

**éªŒè¯**:
```bash
# è™šæ‹Ÿç¯å¢ƒä¸­æµ‹è¯•
(.venv) > python -c "import agent_zyf; print('æ¨¡å—åŠ è½½æˆåŠŸ')"
âœ… æ¨¡å—åŠ è½½æˆåŠŸ
```

#### 2. ç±»å‹é”™è¯¯ä¿®å¤ (æ•°æ®å¤„ç†å®‰å…¨æ€§)

**é—®é¢˜**: `'<=' not supported between instances of 'str' and 'float'`

**æ ¹æœ¬åŸå› **: ä»£ç ç›´æ¥å¯¹åŒ…å«å­—ç¬¦ä¸²çš„åˆ—æ‰§è¡Œæ•°å€¼æ“ä½œï¼Œæœªè¿›è¡Œç±»å‹æ£€æŸ¥å’Œè½¬æ¢

**ä¿®å¤æªæ–½**:
```python
# âŒ åŸæ¥çš„ä¸å®‰å…¨ä»£ç 
min_val = float(data[col].min())  # å¦‚æœåˆ—åŒ…å«å­—ç¬¦ä¸²ä¼šæŠ¥é”™

# âœ… ä¿®å¤åçš„å®‰å…¨ä»£ç   
numeric_data = pd.to_numeric(data[col], errors='coerce').dropna()
if len(numeric_data) == 0:
    print(f"âš ï¸ {col} åˆ—æ²¡æœ‰æœ‰æ•ˆçš„æ•°å€¼æ•°æ®ï¼Œè·³è¿‡å‚æ•°åˆ›å»º")
    continue
min_val = float(numeric_data.min())
max_val = float(numeric_data.max())
```

**åº”ç”¨åˆ°çš„å…³é”®å‡½æ•°**:
- `prepare_baybe_parameters()`: BayBEå‚æ•°åˆ›å»ºæ—¶çš„å®‰å…¨è½¬æ¢
- `analyze_experimental_context()`: å‚æ•°å»ºè®®æ—¶çš„å®‰å…¨è½¬æ¢  
- `_perform_data_quality_check()`: æ•°æ®è´¨é‡æ£€æŸ¥æ—¶çš„å®‰å…¨å¤„ç†
- `_standardize_data()`: æ•°æ®æ ‡å‡†åŒ–æ—¶çš„å®‰å…¨å¤„ç†

**æ–°å¢è¯Šæ–­å·¥å…·**:
```python
def diagnose_data_types(file_path: str) -> str:
    """
    è¯Šæ–­CSVæ•°æ®ä¸­çš„ç±»å‹é—®é¢˜ï¼Œå¸®åŠ©ç”¨æˆ·æ‰¾åˆ°å¯¼è‡´ç±»å‹é”™è¯¯çš„å…·ä½“æ•°æ®
    """
    # è‡ªåŠ¨æ£€æµ‹æ•°å€¼åˆ—ä¸­çš„éæ•°å€¼æ¡ç›®
    # æä¾›å…·ä½“çš„è¡Œå·å’Œé—®é¢˜å€¼
    # ç»™å‡ºä¿®å¤å»ºè®®
```

#### 3. ç‰¹æ®Šç‰©è´¨å¤„ç†é€»è¾‘é‡æ„

**é—®é¢˜**: åŸæ¥çš„"ç‰¹æ®Šåˆ†å­æ£€æµ‹"é€»è¾‘åŸºäºç®€å•å¯å‘å¼è§„åˆ™ï¼Œä¸ç¬¦åˆå®é™…éœ€æ±‚

**æ—§é€»è¾‘é—®é¢˜**:
```python
# âŒ é”™è¯¯çš„å‡è®¾æ€§æ£€æµ‹
class CustomEncodingHandler:
    def detect_special_molecules(self, smiles_list):
        if len(smiles) > 100:  # è¿‡äºç®€å•çš„åˆ¤æ–­
            return "polymer"
        # ç³»ç»Ÿè‡ªä½œä¸»å¼ ç”Ÿæˆç¼–ç ç­–ç•¥
```

**æ–°é€»è¾‘è®¾è®¡**:
```python
# âœ… ç”¨æˆ·å®šä¹‰è¯†åˆ«é€»è¾‘
class UserDefinedEncodingHandler:
    def identify_user_special_substances(self, df):
        """è¯†åˆ«ç”¨æˆ·åœ¨CSVä¸­å®šä¹‰çš„ç‰¹æ®Šç‰©è´¨"""
        # æ£€æµ‹ï¼šæœ‰åç§°ä½†SMILESä¸ºç©ºçš„ç‰©è´¨
        # ç­–ç•¥ï¼šä½¿ç”¨ç”¨æˆ·æä¾›çš„åç§°ä½œä¸ºç¼–ç 
        # ç›®æ ‡ï¼šå°†ç”¨æˆ·ç¼–ç ä¼ é€’ç»™BayBE
```

**æ ¸å¿ƒæ”¹è¿›**:
1. **å°Šé‡ç”¨æˆ·ä¸“ä¸šçŸ¥è¯†**: ä¸å†è‡ªåŠ¨"æ£€æµ‹"ï¼Œè€Œæ˜¯è¯†åˆ«ç”¨æˆ·å®šä¹‰
2. **æ•°æ®é©±åŠ¨**: ä»CSVæ•°æ®ä¸­å‘ç°ç”¨æˆ·çš„ç¼–ç æ„å›¾
3. **æ”¯æŒç‰¹æ®Šç‰©è´¨**: ç¨€é‡Šå‰‚ã€å‚¬åŒ–å‰‚ç­‰æ— SMILESçš„ç‰©è´¨

**å®é™…æ•ˆæœ**:
```python
# ä»æ‚¨çš„ example.csv æ­£ç¡®è¯†åˆ«åˆ°ï¼š
è¯†åˆ«åˆ°ç‰¹æ®Šç‰©è´¨: ç¨€é‡Šå‰‚A, ç¨€é‡Šå‰‚B (æ— SMILESï¼Œä½¿ç”¨åç§°ç¼–ç )
âœ… å°†åˆ›å»º CategoricalParameter ä¼ é€’ç»™BayBE
```

#### 4. æ™ºèƒ½åˆ—åˆ†ç±»ç³»ç»Ÿ

**æ–°åŠŸèƒ½**: åŠ¨æ€è¯†åˆ«6å¤§ç±»æ‰©å±•åˆ—ç±»å‹

```python
class UserDefinedEncodingHandler:
    def __init__(self):
        self.column_type_patterns = {
            "ç‰©ç†æ€§è´¨": {
                "keywords": ["density", "viscosity", "tg", "å¯†åº¦", "ç²˜åº¦", "ç»ç’ƒåŒ–"],
                "baybe_param_type": "NumericalContinuousParameter"
            },
            "åŠŸèƒ½åˆ†ç±»": {
                "keywords": ["catalyst", "additive", "type", "å‚¬åŒ–å‰‚", "æ·»åŠ å‰‚", "ç±»å‹"],
                "baybe_param_type": "CategoricalParameter"  
            },
            "ä¾›åº”å•†ä¿¡æ¯": {
                "keywords": ["supplier", "batch", "grade", "ä¾›åº”å•†", "æ‰¹æ¬¡", "ç­‰çº§"],
                "baybe_param_type": "CategoricalParameter"
            },
            "æˆæœ¬ä¿¡æ¯": {
                "keywords": ["cost", "price", "availability", "æˆæœ¬", "ä»·æ ¼", "å¯è·å¾—æ€§"],
                "baybe_param_type": "NumericalContinuousParameter"
            },
            "å·¥è‰ºå‚æ•°": {
                "keywords": ["temperature", "time", "pressure", "æ¸©åº¦", "æ—¶é—´", "å‹åŠ›"],
                "baybe_param_type": "NumericalContinuousParameter"
            },
            "é…æ–¹ç‰¹æ€§": {
                "keywords": ["hardener", "solvent", "diluent", "å›ºåŒ–å‰‚", "æº¶å‰‚", "ç¨€é‡Šå‰‚"],
                "baybe_param_type": "CategoricalParameter"
            }
        }
```

**æ™ºèƒ½è¯†åˆ«èƒ½åŠ›**:
- âœ… æ”¯æŒä¸­è‹±æ–‡åˆ—åè‡ªåŠ¨è¯†åˆ«
- âœ… è‡ªåŠ¨æ¨æ–­æ•°æ®ç±»å‹ (æ•°å€¼/åˆ†ç±»)  
- âœ… è®¡ç®—è¯†åˆ«ç½®ä¿¡åº¦
- âœ… æä¾›æ•°æ®æ ¼å¼ä¼˜åŒ–å»ºè®®

#### 5. æ ‡å‡†CSVæ ¼å¼ä¸æ··åˆç­–ç•¥

**æ ‡å‡†æ¨¡æ¿**: `standard_template_fixed.csv` (49åˆ—)

```csv
# å®Œæ•´åˆ—ç»“æ„ç¤ºä¾‹
SubstanceA_name,SubstanceA_SMILES,SubstanceA_ratio,SubstanceA_type,SubstanceA_supplier,SubstanceA_grade,SubstanceA_density,SubstanceA_viscosity,SubstanceA_cost_per_kg,SubstanceA_availability,
# ... é‡å¤Bã€Cã€Dç‰©è´¨
Process_temperature,Process_time,Process_pressure,Curing_temperature,Mixing_speed,
Target_mechanical_strength,Target_thermal_stability,Target_chemical_resistance,Target_cost_effectiveness

# ç¤ºä¾‹æ•°æ®
Epoxy_Resin_E51,CC(C)(C1=CC=C(C=C1)OCC2CO2)C3=CC=C(C=C3)OCC4CO4,0.6,epoxy_resin,Supplier_A,Industrial_Grade,1.15,800,25.5,high,...
```

**æ··åˆç­–ç•¥ä¼˜åŠ¿**:
- **é€‰æ‹©A**: ä¿æŒç°æœ‰æ ¼å¼ï¼Œç³»ç»Ÿæ™ºèƒ½é€‚é…
- **é€‰æ‹©B**: ä½¿ç”¨æ ‡å‡†æ ¼å¼ï¼Œè·å¾—æœ€å¼ºåŠŸèƒ½
- **æ¸è¿›è¿ç§»**: å¯é€æ­¥å‘æ ‡å‡†æ ¼å¼è¿‡æ¸¡

#### 6. BayBEå‚æ•°è§„èŒƒä¿®æ­£

**é”™è¯¯å‚æ•°ç§»é™¤**: 
```python
# âŒ ç§»é™¤äº†ä¸å­˜åœ¨çš„å‚æ•°
"æ—¶é—´é™åˆ¶"  # BayBEä¸­ä¸å­˜åœ¨æ­¤å‚æ•°
```

**æ­£ç¡®çš„BayBEå‚æ•°**:
```python
# âœ… BayBEå®é™…æ”¯æŒçš„å®éªŒæ§åˆ¶å‚æ•°
{
    "batch_size": 3,                    # æ¯è½®æ¨èçš„å®éªŒæ•°é‡
    "n_doe_iterations": 10,             # DoEè¿­ä»£è½®æ•°
    "pending_experiments": df_pending,   # æ­£åœ¨è¿›è¡Œçš„å®éªŒ
    "allow_recommending_already_measured": False,
    "allow_recommending_already_recommended": False
}

# çº¦æŸæ¡ä»¶å‚æ•°
from baybe.constraints import (
    ContinuousLinearConstraint,      # è¿ç»­çº¿æ€§çº¦æŸ
    DiscreteCardinalityConstraint,   # ç¦»æ•£åŸºæ•°çº¦æŸ
    DiscreteSumConstraint,          # ç¦»æ•£æ±‚å’Œçº¦æŸ
    DiscreteExcludeConstraint       # ç¦»æ•£æ’é™¤çº¦æŸ
)
```

### ğŸ› ï¸ å¼€å‘å®è·µæŒ‡å—

#### è™šæ‹Ÿç¯å¢ƒè®¾ç½®
```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Windows)
.\.venv\Scripts\Activate.ps1

# éªŒè¯æ¨¡å—åŠ è½½
python -c "import agent_zyf; print('âœ… æ¨¡å—åŠ è½½æˆåŠŸ')"
```

#### æ•°æ®æ ¼å¼æœ€ä½³å®è·µ

**1. æ¨èçš„å‘½åè§„èŒƒ**:
```csv
# ç‰©è´¨ä¿¡æ¯åˆ—
SubstanceX_name          # ç‰©è´¨åç§°
SubstanceX_SMILES        # åˆ†å­ç»“æ„ (å¯ä¸ºç©ºç”¨äºç‰¹æ®Šç‰©è´¨)
SubstanceX_ratio         # æ¯”ä¾‹ (0-1)
SubstanceX_type          # åŠŸèƒ½åˆ†ç±» (resin/hardener/catalyst/solvent/additive)

# æ‰©å±•ä¿¡æ¯åˆ—  
SubstanceX_supplier      # ä¾›åº”å•†
SubstanceX_grade         # ç­‰çº§/çº¯åº¦
SubstanceX_density       # å¯†åº¦ (g/cmÂ³)
SubstanceX_viscosity     # ç²˜åº¦ (PaÂ·s) 
SubstanceX_cost_per_kg   # æˆæœ¬ (å…ƒ/kg)
SubstanceX_availability  # å¯è·å¾—æ€§ (high/medium/low)

# å·¥è‰ºå‚æ•°åˆ—
Process_temperature      # ååº”æ¸©åº¦ (Â°C)
Process_time            # ååº”æ—¶é—´ (min)
Process_pressure        # å‹åŠ› (bar)
Curing_temperature      # å›ºåŒ–æ¸©åº¦ (Â°C)

# ç›®æ ‡å˜é‡åˆ—
Target_XXX              # ç›®æ ‡å˜é‡å
```

**2. ç‰¹æ®Šç‰©è´¨å¤„ç†**:
```csv
# æœ‰SMILESçš„æ ‡å‡†ç‰©è´¨
Epoxy_Resin_E51,CC(C)(C1=CC=C(C=C1)OCC2CO2)C3=CC=C(C=C3)OCC4CO4,0.6

# æ— SMILESçš„ç‰¹æ®Šç‰©è´¨ (ç¨€é‡Šå‰‚ã€ä¸“æœ‰æ·»åŠ å‰‚ç­‰)
Diluent_A,,0.1                    # SMILESç•™ç©ºï¼Œç³»ç»Ÿå°†ä½¿ç”¨åç§°ç¼–ç 
Special_Additive_X,,0.05          # ç³»ç»Ÿè‡ªåŠ¨åˆ›å»º CategoricalParameter
```

#### æ•°æ®ç±»å‹å®‰å…¨æ£€æŸ¥

**æ–°å¢è¯Šæ–­å·¥å…·**:
```python
from agent_zyf.enhanced_verification_tools import diagnose_data_types

# è¯Šæ–­æ•°æ®ç±»å‹é—®é¢˜
result = diagnose_data_types('your_data.csv')
print(result)  # ä¼šæ˜¾ç¤ºå…·ä½“çš„é—®é¢˜è¡Œå’Œä¿®å¤å»ºè®®
```

**ç±»å‹å®‰å…¨çš„ä»£ç æ¨¡å¼**:
```python
# âœ… æ¨èçš„å®‰å…¨è½¬æ¢æ¨¡å¼
def safe_numeric_processing(df, column_name):
    """å®‰å…¨çš„æ•°å€¼åˆ—å¤„ç†æ¨¡å¼"""
    # 1. å°è¯•è½¬æ¢ä¸ºæ•°å€¼
    numeric_data = pd.to_numeric(df[column_name], errors='coerce')
    
    # 2. æ£€æŸ¥æœ‰æ•ˆæ•°æ®æ¯”ä¾‹
    valid_ratio = numeric_data.notna().sum() / len(df)
    if valid_ratio < 0.5:  # å¦‚æœæœ‰æ•ˆæ•°å€¼å°‘äº50%
        print(f"âš ï¸ {column_name} åˆ—æ•°å€¼æ•°æ®ä¸è¶³ï¼Œè·³è¿‡å¤„ç†")
        return None
    
    # 3. å®‰å…¨åœ°è®¡ç®—ç»Ÿè®¡é‡
    clean_data = numeric_data.dropna()
    if len(clean_data) < 2:
        return None
        
    return {
        'min': float(clean_data.min()),
        'max': float(clean_data.max()),
        'mean': float(clean_data.mean())
    }
```

#### Enhanced Verification Agent åŠŸèƒ½æ˜ å°„

**7ä¸ªæ ¸å¿ƒä»»åŠ¡å®ç°**:
```python
def enhanced_verification(file_path: str, tool_context: ToolContext) -> str:
    """
    ä»»åŠ¡1: æ•°æ®è´¨é‡éªŒè¯ - _perform_data_quality_check()
    ä»»åŠ¡2: SMILESéªŒè¯ - SimplifiedSMILESValidator.validate_smiles_data()  
    ä»»åŠ¡3: æ™ºèƒ½å‚æ•°å»ºè®® - IntelligentParameterAdvisor.analyze_experimental_context()
    ä»»åŠ¡4: ç”¨æˆ·å®šä¹‰ç¼–ç è¯†åˆ« - UserDefinedEncodingHandler.identify_user_special_substances()
    ä»»åŠ¡5: ç”¨æˆ·äº¤äº’ - _generate_user_interaction_prompt()
    ä»»åŠ¡6: å‚æ•°é…ç½®å‡†å¤‡ - collect_optimization_goals()
    ä»»åŠ¡7: æ•°æ®æ ‡å‡†åŒ– - _standardize_data()
    """
```

**é‡æ„çš„æ ¸å¿ƒç±»**:
```python
# æ–°ç±»æ›¿æ¢æ—§ç±»
UserDefinedEncodingHandler  # æ›¿æ¢ CustomEncodingHandler
â”œâ”€â”€ identify_user_special_substances()      # è¯†åˆ«ç‰¹æ®Šç‰©è´¨
â”œâ”€â”€ classify_user_columns()                # æ™ºèƒ½åˆ—åˆ†ç±»
â”œâ”€â”€ create_baybe_parameters_for_special_substances()  # åˆ›å»ºBayBEå‚æ•°
â””â”€â”€ generate_standard_csv_template()       # ç”Ÿæˆæ ‡å‡†æ¨¡æ¿
```

#### å·¥å…·å‡½æ•°æ›´æ–°

**Enhanced Verification Agent å·¥å…·é›†**:
```python
enhanced_verification_agent = LlmAgent(
    name="enhanced_verification_agent",
    tools=[
        enhanced_verification,           # ä¸»è¦éªŒè¯åŠŸèƒ½ (7ä¸ªä»»åŠ¡)
        collect_optimization_goals,      # æ”¶é›†ç”¨æˆ·ä¼˜åŒ–ç›®æ ‡  
        diagnose_data_types,            # ğŸ†• è¯Šæ–­æ•°æ®ç±»å‹é—®é¢˜
        tools.verification,              # ä¿ç•™åŸæœ‰éªŒè¯ä½œä¸ºå¤‡ç”¨
    ]
)
```

#### BayBEé›†æˆè§„èŒƒæ›´æ–°

**æ­£ç¡®çš„å‚æ•°é…ç½®**:
```python
# âœ… BayBEå®é™…æ”¯æŒçš„é…ç½®å‚æ•°
campaign_config = {
    "batch_size": int,                    # æ¯è½®å®éªŒæ•°é‡
    "n_doe_iterations": int,              # æœ€å¤§è¿­ä»£è½®æ•°  
    "total_budget": int,                  # æ€»å®éªŒé¢„ç®— (è‡ªå®šä¹‰çº¦æŸ)
    "allow_recommending_already_measured": bool,
    "allow_recommending_already_recommended": bool
}

# âŒ ç§»é™¤çš„é”™è¯¯å‚æ•°  
# "time_limit": ä¸å­˜åœ¨äºBayBEä¸­
```

**çº¦æŸæ¡ä»¶ç¤ºä¾‹**:
```python
from baybe.constraints import ContinuousLinearConstraint, DiscreteSumConstraint

# æ¯”ä¾‹å’Œçº¦æŸ (ç¡®ä¿æ‰€æœ‰æ¯”ä¾‹ä¹‹å’Œä¸º1)
ratio_constraint = ContinuousLinearConstraint(
    parameters=["SubstanceA_ratio", "SubstanceB_ratio", "SubstanceC_ratio"],
    operator="=",
    coefficients=[1.0, 1.0, 1.0], 
    rhs=1.0
)

# æ¸©åº¦èŒƒå›´çº¦æŸ
temperature_constraint = ContinuousLinearConstraint(
    parameters=["Process_temperature"],
    operator="<=",
    coefficients=[1.0],
    rhs=200.0  # æœ€é«˜200Â°C
)
```

### ğŸš€ è¿ç§»æŒ‡å—

#### ä»æ—§ç‰ˆæœ¬è¿ç§»

**1. ä»£ç æ›´æ–°**:
```python
# æ›´æ–°å¯¼å…¥
from agent_zyf.enhanced_verification_tools import (
    UserDefinedEncodingHandler,  # æ–°ç±»
    diagnose_data_types,         # æ–°å·¥å…·
    enhanced_verification
)

# æ›´æ–°ç±»å
encoder = UserDefinedEncodingHandler()  # æ›¿æ¢ CustomEncodingHandler
```

**2. æ•°æ®æ ¼å¼æ£€æŸ¥**:
```python
# ä½¿ç”¨æ–°çš„è¯Šæ–­å·¥å…·æ£€æŸ¥æ•°æ®
diagnosis_result = diagnose_data_types('your_data.csv')
print(diagnosis_result)  # ä¼šæ˜¾ç¤ºæ‰€æœ‰ç±»å‹é—®é¢˜
```

**3. é…ç½®å‚æ•°æ›´æ–°**:
```python
# ç§»é™¤é”™è¯¯å‚æ•°
config = {
    "batch_size": 5,
    "n_doe_iterations": 20,
    # "time_limit": åˆ é™¤  # âŒ BayBEä¸­ä¸å­˜åœ¨
    "budget_limit": 100  # âœ… ä½¿ç”¨æ€»å®éªŒæ•°é‡é™åˆ¶
}
```

### ğŸ¯ æœ€ä½³å®è·µå»ºè®®

#### 1. æ•°æ®å‡†å¤‡
- ä¼˜å…ˆä½¿ç”¨ `standard_template_fixed.csv` ä½œä¸ºæ ¼å¼å‚è€ƒ
- ä¿æŒç°æœ‰æ ¼å¼ä¹Ÿå®Œå…¨æ”¯æŒ (ç³»ç»Ÿæ™ºèƒ½é€‚é…)
- æ•°å€¼åˆ—ç¡®ä¿çº¯æ•°å­—ï¼Œé¿å…æ··åˆå­—ç¬¦ä¸²

#### 2. ç‰¹æ®Šç‰©è´¨å¤„ç†
- æœ‰SMILESï¼šæ­£å¸¸çš„åˆ†å­å‚æ•°
- æ— SMILESï¼šåœ¨åç§°åˆ—å¡«å†™ç‰©è´¨åï¼ŒSMILESåˆ—ç•™ç©º
- ç³»ç»Ÿä¼šè‡ªåŠ¨ä¸ºç‰¹æ®Šç‰©è´¨åˆ›å»ºåˆé€‚çš„BayBEå‚æ•°

#### 3. å¼€å‘è°ƒè¯•
- ä½¿ç”¨ `diagnose_data_types()` æ’æŸ¥æ•°æ®é—®é¢˜
- åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å¼€å‘å’Œæµ‹è¯•
- å…³æ³¨linteræç¤ºï¼Œä¿æŒä»£ç è´¨é‡

### ğŸ“‹ éªŒè¯æ¸…å•

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯ç³»ç»ŸçŠ¶æ€ï¼š
```bash
# 1. æ¨¡å—å¯¼å…¥æµ‹è¯•
python -c "import agent_zyf; print('âœ… æ¨¡å—å¯¼å…¥æ­£å¸¸')"

# 2. åŠŸèƒ½ç»„ä»¶æµ‹è¯•  
python -c "from agent_zyf.enhanced_verification_tools import UserDefinedEncodingHandler, diagnose_data_types; print('âœ… æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸')"

# 3. æ•°æ®è¯Šæ–­æµ‹è¯•
python -c "from agent_zyf.enhanced_verification_tools import diagnose_data_types; print(diagnose_data_types('example.csv'))"
```

### ğŸ”„ æŒç»­ç»´æŠ¤

- å®šæœŸæ›´æ–°BayBEåˆ°æœ€æ–°ç‰ˆæœ¬
- æ‰©å±•column_type_patternsä»¥æ”¯æŒæ›´å¤šåˆ—ç±»å‹
- æ ¹æ®å®é™…ä½¿ç”¨åé¦ˆä¼˜åŒ–æ™ºèƒ½è¯†åˆ«è§„åˆ™
- ä¿æŒä¸Google ADKè§„èŒƒçš„å…¼å®¹æ€§
