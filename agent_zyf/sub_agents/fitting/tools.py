# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Fitting Agent Tools - æ¨¡å‹åˆ†æä¸å¯è§†åŒ–"""

import os
import pandas as pd
import numpy as np
import json
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from google.adk.tools import ToolContext

# BayBEå’Œæœºå™¨å­¦ä¹ å¯¼å…¥
try:
    from baybe import Campaign
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.metrics import mean_squared_error, r2_score
    from sklearn.model_selection import cross_val_score
    BAYBE_AVAILABLE = True
    ML_AVAILABLE = True
except ImportError as e:
    print(f"Warning: æŸäº›ä¾èµ–æœªå®‰è£…: {e}")
    BAYBE_AVAILABLE = False
    ML_AVAILABLE = False


def analyze_campaign_performance(tool_context: ToolContext) -> str:
    """
    åˆ†æBayBE Campaignçš„æ€§èƒ½å’Œä¼˜åŒ–æ•ˆæœ
    """
    state = tool_context.state
    session_id = state.get("session_id", "unknown")
    
    if not BAYBE_AVAILABLE:
        return "âŒ BayBEæœªå®‰è£…ï¼Œæ— æ³•è¿›è¡Œæ€§èƒ½åˆ†æã€‚"
    
    try:
        campaign = state.get("baybe_campaign")
        current_round = state.get("optimization_round", 0)
        
        if not campaign:
            return "âŒ æœªæ‰¾åˆ°BayBE Campaignã€‚"
        
        if not hasattr(campaign, 'measurements') or len(campaign.measurements) < 3:
            return f"""
ğŸ“Š **Campaignæ€§èƒ½åˆ†æ** (è½®æ¬¡ {current_round})

âš ï¸ **æ•°æ®ä¸è¶³**: å½“å‰å®éªŒæ•°é‡ {len(campaign.measurements) if hasattr(campaign, 'measurements') else 0}

ğŸ” **å»ºè®®**: è‡³å°‘éœ€è¦3-5è½®å®éªŒæ•°æ®æ‰èƒ½è¿›è¡Œæœ‰æ•ˆçš„æ€§èƒ½åˆ†æ

ğŸ“ˆ **å¯ç”¨åˆ†æ** (å½“æœ‰è¶³å¤Ÿæ•°æ®æ—¶):
- ä¼˜åŒ–è½¨è¿¹å¯è§†åŒ–
- ç›®æ ‡å€¼æ”¹è¿›è¶‹åŠ¿
- å‚æ•°é‡è¦æ€§åˆ†æ
- ä»£ç†æ¨¡å‹æ€§èƒ½è¯„ä¼°
- æ”¶æ•›æ€§è¯Šæ–­
            """
        
        # æ‰§è¡Œè¯¦ç»†çš„æ€§èƒ½åˆ†æ
        performance_results = _detailed_performance_analysis(campaign, current_round)
        
        # ç”Ÿæˆå¯è§†åŒ–
        viz_files = _generate_visualizations(campaign, session_id)
        
        # æ›´æ–°çŠ¶æ€
        state["performance_analysis"] = performance_results
        state["visualization_files"] = viz_files
        state["analysis_timestamp"] = datetime.now().isoformat()
        
        return _format_performance_report(performance_results, viz_files, current_round)
        
    except Exception as e:
        return f"âŒ æ€§èƒ½åˆ†æå¤±è´¥: {str(e)}"


def create_interpretable_model(tool_context: ToolContext) -> str:
    """
    åˆ›å»ºå¯è§£é‡Šçš„ä»£ç†æ¨¡å‹
    """
    state = tool_context.state
    
    if not (BAYBE_AVAILABLE and ML_AVAILABLE):
        return "âŒ ç¼ºå°‘å¿…è¦ä¾èµ–ï¼Œæ— æ³•åˆ›å»ºä»£ç†æ¨¡å‹ã€‚"
    
    try:
        campaign = state.get("baybe_campaign")
        
        if not campaign or not hasattr(campaign, 'measurements') or len(campaign.measurements) < 5:
            return "âš ï¸ å®éªŒæ•°æ®ä¸è¶³ï¼Œæ— æ³•è®­ç»ƒå¯é çš„ä»£ç†æ¨¡å‹ã€‚å»ºè®®è‡³å°‘è¿›è¡Œ5è½®å®éªŒã€‚"
        
        # æå–ç‰¹å¾å’Œç›®æ ‡
        measurements = campaign.measurements
        feature_columns = [col for col in measurements.columns if not col.startswith('Target_')]
        target_columns = [col for col in measurements.columns if col.startswith('Target_')]
        
        interpretable_results = {}
        
        # ä¸ºæ¯ä¸ªç›®æ ‡åˆ›å»ºä»£ç†æ¨¡å‹
        for target in target_columns:
            if target in measurements.columns:
                X = measurements[feature_columns]
                y = measurements[target]
                
                # å¤„ç†åˆ†ç±»ç‰¹å¾ï¼ˆåˆ†å­å‚æ•°ï¼‰
                X_processed = _preprocess_features_for_ml(X, campaign)
                
                # è®­ç»ƒéšæœºæ£®æ—ï¼ˆå¯è§£é‡Šæ€§å¥½ï¼‰
                rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
                rf_model.fit(X_processed, y)
                
                # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
                y_pred = rf_model.predict(X_processed)
                r2 = r2_score(y, y_pred)
                rmse = np.sqrt(mean_squared_error(y, y_pred))
                
                # ç‰¹å¾é‡è¦æ€§
                feature_importance = dict(zip(X_processed.columns, rf_model.feature_importances_))
                top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
                
                interpretable_results[target] = {
                    "r2_score": r2,
                    "rmse": rmse,
                    "top_features": top_features,
                    "model_quality": "good" if r2 > 0.8 else "moderate" if r2 > 0.6 else "poor"
                }
        
        # ä¿å­˜ç»“æœ
        state["interpretable_models"] = interpretable_results
        
        return _format_interpretable_model_report(interpretable_results)
        
    except Exception as e:
        return f"âŒ ä»£ç†æ¨¡å‹åˆ›å»ºå¤±è´¥: {str(e)}"


def generate_optimization_report(report_type: str, tool_context: ToolContext) -> str:
    """
    ç”Ÿæˆç»¼åˆä¼˜åŒ–æŠ¥å‘Š
    
    Args:
        report_type: æŠ¥å‘Šç±»å‹ ("summary" | "detailed" | "publication")
    """
    state = tool_context.state
    session_id = state.get("session_id", "unknown")
    
    try:
        campaign = state.get("baybe_campaign")
        performance_analysis = state.get("performance_analysis", {})
        interpretable_models = state.get("interpretable_models", {})
        current_round = state.get("optimization_round", 0)
        
        if not campaign:
            return "âŒ æœªæ‰¾åˆ°BayBE Campaignæ•°æ®ã€‚"
        
        # æ ¹æ®æŠ¥å‘Šç±»å‹ç”Ÿæˆä¸åŒè¯¦ç»†ç¨‹åº¦çš„æŠ¥å‘Š
        if report_type == "summary":
            report = _generate_summary_report(campaign, current_round, performance_analysis)
        elif report_type == "detailed":
            report = _generate_detailed_report(campaign, performance_analysis, interpretable_models)
        elif report_type == "publication":
            report = _generate_publication_ready_report(campaign, performance_analysis, interpretable_models)
        else:
            report = _generate_summary_report(campaign, current_round, performance_analysis)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = f"optimization_report_{report_type}_{session_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        state["latest_report"] = report_file
        
        return f"""
ğŸ“„ **ä¼˜åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ**

ğŸ“Š **æŠ¥å‘Šç±»å‹**: {report_type}
ğŸ“ **æ–‡ä»¶è·¯å¾„**: {report_file}

{report}
        """
        
    except Exception as e:
        return f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}"


# è¾…åŠ©å‡½æ•°
def _detailed_performance_analysis(campaign, current_round):
    """è¯¦ç»†æ€§èƒ½åˆ†æ"""
    measurements = campaign.measurements
    targets = [t.name for t in campaign.objective.targets]
    
    analysis = {
        "total_experiments": len(measurements),
        "optimization_rounds": current_round,
        "target_analysis": {},
        "optimization_efficiency": "unknown"
    }
    
    for target in targets:
        if target in measurements.columns:
            values = measurements[target].values
            analysis["target_analysis"][target] = {
                "best_value": float(np.max(values)),
                "worst_value": float(np.min(values)),
                "mean_value": float(np.mean(values)),
                "std_value": float(np.std(values)),
                "improvement_ratio": float((np.max(values) - values[0]) / abs(values[0])) if values[0] != 0 else 0
            }
    
    return analysis


def _generate_visualizations(campaign, session_id):
    """ç”Ÿæˆä¼˜åŒ–è¿‡ç¨‹å¯è§†åŒ–"""
    if not hasattr(campaign, 'measurements') or len(campaign.measurements) < 3:
        return []
    
    viz_files = []
    measurements = campaign.measurements
    targets = [t.name for t in campaign.objective.targets]
    
    try:
        # 1. ä¼˜åŒ–è½¨è¿¹å›¾
        plt.figure(figsize=(12, 8))
        
        for i, target in enumerate(targets):
            if target in measurements.columns:
                plt.subplot(2, 2, i+1)
                values = measurements[target].values
                plt.plot(values, marker='o')
                plt.title(f'{target} ä¼˜åŒ–è½¨è¿¹')
                plt.xlabel('å®éªŒè½®æ¬¡')
                plt.ylabel(target)
                plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        viz_file = f"optimization_trajectory_{session_id}.png"
        plt.savefig(viz_file, dpi=300, bbox_inches='tight')
        plt.close()
        viz_files.append(viz_file)
        
        # 2. ç›®æ ‡å€¼åˆ†å¸ƒå›¾
        if len(targets) >= 2:
            plt.figure(figsize=(10, 8))
            
            for i, target in enumerate(targets[:3]):  # æœ€å¤šæ˜¾ç¤º3ä¸ªç›®æ ‡
                plt.subplot(2, 2, i+1)
                if target in measurements.columns:
                    plt.hist(measurements[target], bins=10, alpha=0.7)
                    plt.title(f'{target} åˆ†å¸ƒ')
                    plt.xlabel(target)
                    plt.ylabel('é¢‘æ¬¡')
            
            plt.tight_layout()
            viz_file = f"target_distributions_{session_id}.png"
            plt.savefig(viz_file, dpi=300, bbox_inches='tight')
            plt.close()
            viz_files.append(viz_file)
            
    except Exception as e:
        print(f"å¯è§†åŒ–ç”Ÿæˆè­¦å‘Š: {e}")
    
    return viz_files


def _preprocess_features_for_ml(X, campaign):
    """ä¸ºæœºå™¨å­¦ä¹ é¢„å¤„ç†ç‰¹å¾"""
    X_processed = X.copy()
    
    # å¤„ç†åˆ†ç±»å˜é‡ï¼ˆåˆ†å­å‚æ•°ï¼‰
    for param_name in campaign.searchspace.parameter_names:
        if param_name in X_processed.columns:
            if X_processed[param_name].dtype == 'object':
                # åˆ†ç±»ç¼–ç 
                X_processed[param_name] = pd.factorize(X_processed[param_name])[0]
    
    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯æ•°å€¼ç±»å‹
    X_processed = X_processed.select_dtypes(include=[np.number])
    
    return X_processed


def _format_performance_report(performance_results, viz_files, current_round):
    """æ ¼å¼åŒ–æ€§èƒ½æŠ¥å‘Š"""
    report = f"""
ğŸ“Š **Campaignæ€§èƒ½åˆ†æå®Œæˆ** (è½®æ¬¡ {current_round})

ğŸ“ˆ **å®éªŒç»Ÿè®¡**:
- æ€»å®éªŒæ•°: {performance_results.get('total_experiments', 0)}
- ä¼˜åŒ–è½®æ¬¡: {performance_results.get('optimization_rounds', 0)}

ğŸ¯ **ç›®æ ‡åˆ†æ**:
"""
    
    target_analysis = performance_results.get("target_analysis", {})
    for target, analysis in target_analysis.items():
        report += f"""
ğŸ“Œ **{target}**:
   - æœ€ä½³å€¼: {analysis.get('best_value', 'N/A'):.3f}
   - å¹³å‡å€¼: {analysis.get('mean_value', 'N/A'):.3f}
   - æ”¹è¿›æ¯”ä¾‹: {analysis.get('improvement_ratio', 0):.1%}
"""
    
    if viz_files:
        report += f"\nğŸ“Š **å¯è§†åŒ–æ–‡ä»¶**: {len(viz_files)} ä¸ªå›¾è¡¨å·²ç”Ÿæˆ\n"
        for viz_file in viz_files:
            report += f"   - {viz_file}\n"
    
    report += "\nğŸš€ **åˆ†æå®Œæˆ**: å¯ä»¥ä½¿ç”¨ generate_optimization_report å·¥å…·ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"
    
    return report


def _format_interpretable_model_report(interpretable_results):
    """æ ¼å¼åŒ–å¯è§£é‡Šæ¨¡å‹æŠ¥å‘Š"""
    report = """
ğŸ¤– **ä»£ç†æ¨¡å‹åˆ†æå®Œæˆ**

ğŸ“Š **æ¨¡å‹æ€§èƒ½æ‘˜è¦**:
"""
    
    for target, results in interpretable_results.items():
        report += f"""
ğŸ¯ **{target}**:
   - RÂ² è¯„åˆ†: {results['r2_score']:.3f}
   - RMSE: {results['rmse']:.3f}
   - æ¨¡å‹è´¨é‡: {results['model_quality']}
   
   ğŸ” **é‡è¦ç‰¹å¾** (Top 5):
"""
        for feature, importance in results['top_features']:
            report += f"      {feature}: {importance:.3f}\n"
    
    return report


def _generate_summary_report(campaign, current_round, performance_analysis):
    """ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š"""
    return f"""
ğŸ¯ ChemBoMAS ä¼˜åŒ–æ‘˜è¦æŠ¥å‘Š

ğŸ“Š åŸºæœ¬ä¿¡æ¯:
- ä¼˜åŒ–è½®æ¬¡: {current_round}
- æ€»å®éªŒæ•°: {len(campaign.measurements) if hasattr(campaign, 'measurements') else 0}
- å‚æ•°æ•°é‡: {len(campaign.searchspace.parameter_names)}
- ç›®æ ‡æ•°é‡: {len(campaign.objective.targets)}

ğŸ“ˆ ä¼˜åŒ–æ•ˆæœ: 
{json.dumps(performance_analysis.get('target_analysis', {}), indent=2, ensure_ascii=False)}
    """